
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["宋丛溪"],"categories":null,"content":"\n宋丛溪，2020级在读博士。2013年考入北京航空航天大学计算机科学与技术专业，获得工学学士学位，2017年保送国防科技大学计算机科学与技术专业研究生，2019年获得工学硕士学位，于同年通过“申请-审核”在国防科技大学网络空间专业攻读博士学位。\n从2017年至今，从事漏洞挖掘、多路径传输、智能网络等方向的研究。曾以第一作者发表SCI论文2篇，中文核心期刊论文1篇。 ","date":1696647165,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1696647165,"objectID":"d1e42a1dcd56816bf12105220ad9c436","permalink":"https://ai4network.github.io/zh/author/%E5%AE%8B%E4%B8%9B%E6%BA%AA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%AE%8B%E4%B8%9B%E6%BA%AA/","section":"authors","summary":"\n宋丛溪，2020级在读博士。2013年考入北京航空航天大学计算机科学与技术专业，获得工学学士学位，2017年保送国防科技大学计算机科学与技术专业研究生，2019年获得工学硕士学位，于同年通过“申请-审核”在国防科技大学网络空间专业攻读博士学位。\n从2017年至今，从事漏洞挖掘、多路径传输、智能网络等方向的研究。曾以第一作者发表SCI论文2篇，中文核心期刊论文1篇。 ","tags":null,"title":"宋丛溪","type":"authors"},{"authors":["韩雪强"],"categories":null,"content":"","date":1684914765,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1684914765,"objectID":"ebfd765f8c81394f18ccd958905bc14a","permalink":"https://ai4network.github.io/zh/author/%E9%9F%A9%E9%9B%AA%E5%BC%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%9F%A9%E9%9B%AA%E5%BC%BA/","section":"authors","summary":"","tags":null,"title":"韩雪强","type":"authors"},{"authors":["计晓岚"],"categories":null,"content":"计晓岚，国防科技大学，2020级硕士研究生。2016年考入国防科技大学计算机科学与技术专业，2020年通过硕士推免，至今就读于国防科技大学网络空间安全专业。研究方向围绕智能网络，主要研究智能多路径传输优化、拥塞控制智能优化技术。智能多路径拥塞控制优化相关研究成果，应用于某智能网络新型机制基础研究项目，作为无人机智能多路径直播系统的关键技术之一获得2021年中国高校计算机大赛网络技术挑战赛全国二等奖，于IWQoS2022（CCF B类会议）发表\u0026#34;ACCeSS: Adaptive QoS-aware Congestion Control for Multipath TCP\u0026#34;[DOI: 10.1109/IWQoS54832.2022.9812886]。\n照片仅供参考，实际头秃菜鸟。\n","date":1680291000,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1680291000,"objectID":"c01de57a5ef618f9f02c8f30cf33b381","permalink":"https://ai4network.github.io/zh/author/%E8%AE%A1%E6%99%93%E5%B2%9A/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E8%AE%A1%E6%99%93%E5%B2%9A/","section":"authors","summary":"计晓岚，国防科技大学，2020级硕士研究生。2016年考入国防科技大学计算机科学与技术专业，2020年通过硕士推免，至今就读于国防科技大学网络空间安全专业。研究方向围绕智能网络，主要研究智能多路径传输优化、拥塞控制智能优化技术。智能多路径拥塞控制优化相关研究成果，应用于某智能网络新型机制基础研究项目，作为无人机智能多路径直播系统的关键技术之一获得2021年中国高校计算机大赛网络技术挑战赛全国二等奖，于IWQoS2022（CCF B类会议）发表\"ACCeSS: Adaptive QoS-aware Congestion Control for Multipath TCP\"[DOI: 10.1109/IWQoS54832.2022.9812886]。\n照片仅供参考，实际头秃菜鸟。","tags":null,"title":"计晓岚","type":"authors"},{"authors":["黄鑫"],"categories":null,"content":"黄鑫，国防科技大学，2022级硕士。2018年考入东北大学软件学院，2022年取得信息安全学士学位。2021年推免为国防科技大学计算机学院2022级硕士生。\n","date":1674031355,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1674031355,"objectID":"16aa3715d25f52ce86b51291c7b0d360","permalink":"https://ai4network.github.io/zh/author/%E9%BB%84%E9%91%AB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%BB%84%E9%91%AB/","section":"authors","summary":"黄鑫，国防科技大学，2022级硕士。2018年考入东北大学软件学院，2022年取得信息安全学士学位。2021年推免为国防科技大学计算机学院2022级硕士生。","tags":null,"title":"黄鑫","type":"authors"},{"authors":["梁观平"],"categories":null,"content":"梁观平，国防科技大学直博生。2017年考入桂林电子科技大学信息与通信学院，2019年转专业至计算机与信息安全学院物联网工程专业。2021年推免为国防科技大学计算机学院2022级直博生。\n","date":1673336406,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1673336406,"objectID":"ff01d7ccd05bcb21bf014ae1fe108a0d","permalink":"https://ai4network.github.io/zh/author/%E6%A2%81%E8%A7%82%E5%B9%B3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%A2%81%E8%A7%82%E5%B9%B3/","section":"authors","summary":"梁观平，国防科技大学直博生。2017年考入桂林电子科技大学信息与通信学院，2019年转专业至计算机与信息安全学院物联网工程专业。2021年推免为国防科技大学计算机学院2022级直博生。","tags":null,"title":"梁观平","type":"authors"},{"authors":["陈鑫"],"categories":null,"content":"陈鑫，国防科技大学2022级硕士生。2018年考入吉林大学计算机科学与技术学院，2021年推免为国防科技大学计算机学院2022级硕士生。\n","date":1672817567,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1672817567,"objectID":"c599f67022c450379b663e5b5069d9ef","permalink":"https://ai4network.github.io/zh/author/%E9%99%88%E9%91%AB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%99%88%E9%91%AB/","section":"authors","summary":"陈鑫，国防科技大学2022级硕士生。2018年考入吉林大学计算机科学与技术学院，2021年推免为国防科技大学计算机学院2022级硕士生。","tags":null,"title":"陈鑫","type":"authors"},{"authors":["李亚辉"],"categories":null,"content":"","date":1670009400,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1670009400,"objectID":"09441090aaa4608f8f2e174632f7c189","permalink":"https://ai4network.github.io/zh/author/%E6%9D%8E%E4%BA%9A%E8%BE%89/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%9D%8E%E4%BA%9A%E8%BE%89/","section":"authors","summary":"","tags":null,"title":"李亚辉","type":"authors"},{"authors":["徐草"],"categories":null,"content":"","date":1669553896,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1669553896,"objectID":"b190b5be962440c0a030c3e2d3b807dd","permalink":"https://ai4network.github.io/zh/author/%E5%BE%90%E8%8D%89/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%BE%90%E8%8D%89/","section":"authors","summary":"","tags":null,"title":"徐草","type":"authors"},{"authors":["蔡阳"],"categories":null,"content":"蔡阳，硕士，助理工程师。2015年考入中南大学信息安全专业，2019获得学士学位，并推免至国防科技大学网络空间安全专业学习，2021年获硕士学位。2022年2月起就职于西安某单位，任助理工程师，从事网络管理相关工作。\n硕士期间主要从事智能运维、多路径网络传输协议、入侵检测等方面的研究。参与智能网络相关科研项目1项，相关研究成果发表一篇CCF B类会议论文，一篇CCF C类会议论文，申请专利2项。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"8781ffeb89d3ecccfa96769311d6fbf4","permalink":"https://ai4network.github.io/zh/author/%E8%94%A1%E9%98%B3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E8%94%A1%E9%98%B3/","section":"authors","summary":"蔡阳，硕士，助理工程师。2015年考入中南大学信息安全专业，2019获得学士学位，并推免至国防科技大学网络空间安全专业学习，2021年获硕士学位。2022年2月起就职于西安某单位，任助理工程师，从事网络管理相关工作。\n硕士期间主要从事智能运维、多路径网络传输协议、入侵检测等方面的研究。参与智能网络相关科研项目1项，相关研究成果发表一篇CCF B类会议论文，一篇CCF C类会议论文，申请专利2项。","tags":null,"title":"蔡阳","type":"authors"},{"authors":["陈奕棠"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"d58f831ac5bb9403b929217563fdab44","permalink":"https://ai4network.github.io/zh/author/%E9%99%88%E5%A5%95%E6%A3%A0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%99%88%E5%A5%95%E6%A3%A0/","section":"authors","summary":"","tags":null,"title":"陈奕棠","type":"authors"},{"authors":["丁立"],"categories":null,"content":"就职情况：2021年7月就职于中国电子科技集团公司第二十八研究所\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"65304700855b395a31cbb17b0b2165d4","permalink":"https://ai4network.github.io/zh/author/%E4%B8%81%E7%AB%8B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E4%B8%81%E7%AB%8B/","section":"authors","summary":"就职情况：2021年7月就职于中国电子科技集团公司第二十八研究所","tags":null,"title":"丁立","type":"authors"},{"authors":["韩彪"],"categories":null,"content":"韩彪，博士，副研究员。2003年考入国防科技大学计算机科学与技术专业，先后获学士学位、硕士推免并提前攻博，2009年12月获国家教育部留学基金委“建设高水平大学”项目资助，赴日本筑波大学系统情报与工学研究科攻读博士学位，2013年7月获日本筑波大学博士学位，专业为计算机科学。自2013年8月起就职于国防科技大学计算机学院，2018年晋升为副研究员职称。\n从2007年至今，一直从事智能网络、无人集群网络和网络空间安全等方面研究工作，主持及承担多个重要科研项目10余项，形成无人网络智能生成机理与协议体系，在自主路由决策、分组转发策略与内生安全防护等方面，取得了一系列独创性研究成果。\n入选“湖湘青年英才”、“湖湘青年科技创新人才”、“长沙市杰出创新青年培养计划”，国防科技大学第二批高层次人才培养对象、国防科技大学“青年创新奖”。获省部级科技进步奖1项，申请/授权发明专利22项，在IEEE Trans等国内外权威期刊和会议发表论文60余篇。代表性成果包括以第一/通信作者发表顶级期刊/会议论文9篇，最高影响因子8.6，累计引用800余次，获国际会议最佳论文奖1项，出版专著章节1部，入选2014年海德堡获奖者论坛论坛遴选的全球100名优秀计算机青年科学家并受邀参会。担任中国计算机学会网络与数据通信专委、互联网专委委员。担任多个网络领域权威期刊的编委及国际会议程序委员会委员，指导（含协助指导）博士/硕士研究生20余人。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"1fcc6e0db836616abbe1ace433b37a32","permalink":"https://ai4network.github.io/zh/author/%E9%9F%A9%E5%BD%AA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%9F%A9%E5%BD%AA/","section":"authors","summary":"韩彪，博士，副研究员。2003年考入国防科技大学计算机科学与技术专业，先后获学士学位、硕士推免并提前攻博，2009年12月获国家教育部留学基金委“建设高水平大学”项目资助，赴日本筑波大学系统情报与工学研究科攻读博士学位，2013年7月获日本筑波大学博士学位，专业为计算机科学。自2013年8月起就职于国防科技大学计算机学院，2018年晋升为副研究员职称。\n从2007年至今，一直从事智能网络、无人集群网络和网络空间安全等方面研究工作，主持及承担多个重要科研项目10余项，形成无人网络智能生成机理与协议体系，在自主路由决策、分组转发策略与内生安全防护等方面，取得了一系列独创性研究成果。\n入选“湖湘青年英才”、“湖湘青年科技创新人才”、“长沙市杰出创新青年培养计划”，国防科技大学第二批高层次人才培养对象、国防科技大学“青年创新奖”。获省部级科技进步奖1项，申请/授权发明专利22项，在IEEE Trans等国内外权威期刊和会议发表论文60余篇。代表性成果包括以第一/通信作者发表顶级期刊/会议论文9篇，最高影响因子8.6，累计引用800余次，获国际会议最佳论文奖1项，出版专著章节1部，入选2014年海德堡获奖者论坛论坛遴选的全球100名优秀计算机青年科学家并受邀参会。担任中国计算机学会网络与数据通信专委、互联网专委委员。担任多个网络领域权威期刊的编委及国际会议程序委员会委员，指导（含协助指导）博士/硕士研究生20余人。","tags":null,"title":"韩彪","type":"authors"},{"authors":["黄锦森"],"categories":null,"content":"2014年考入长春理工大学信息对抗技术专业，2019年考入国防科技大学，现就职于华为云计算公司。在研期间主要从事物理层安全的研究，参与相关科研项目一项，发表学术论文一篇，专利授权一篇。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"45af3e79ef78e9959c72a4d56c25810f","permalink":"https://ai4network.github.io/zh/author/%E9%BB%84%E9%94%A6%E6%A3%AE/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%BB%84%E9%94%A6%E6%A3%AE/","section":"authors","summary":"2014年考入长春理工大学信息对抗技术专业，2019年考入国防科技大学，现就职于华为云计算公司。在研期间主要从事物理层安全的研究，参与相关科研项目一项，发表学术论文一篇，专利授权一篇。","tags":null,"title":"黄锦森","type":"authors"},{"authors":["鞠翔宇"],"categories":null,"content":"鞠翔宇，国防科技大学，2023级硕士研究生。2019年考入国防科技大学计算机科学与技术专业，2023年通过硕士推免，至今就读于国防科技大学计算机科学与技术专业。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"86d3fed728aa31b95a54344202414cd2","permalink":"https://ai4network.github.io/zh/author/%E9%9E%A0%E7%BF%94%E5%AE%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%9E%A0%E7%BF%94%E5%AE%87/","section":"authors","summary":"鞠翔宇，国防科技大学，2023级硕士研究生。2019年考入国防科技大学计算机科学与技术专业，2023年通过硕士推免，至今就读于国防科技大学计算机科学与技术专业。","tags":null,"title":"鞠翔宇","type":"authors"},{"authors":["李金融"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"0bc9e287fec71bf61d788102248104e1","permalink":"https://ai4network.github.io/zh/author/%E6%9D%8E%E9%87%91%E8%9E%8D/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%9D%8E%E9%87%91%E8%9E%8D/","section":"authors","summary":"","tags":null,"title":"李金融","type":"authors"},{"authors":["李龙"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"7116642afa1aa016fdbdc9bb11ad24c2","permalink":"https://ai4network.github.io/zh/author/%E6%9D%8E%E9%BE%99/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%9D%8E%E9%BE%99/","section":"authors","summary":"","tags":null,"title":"李龙","type":"authors"},{"authors":["李志强"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"f9cccdc794bd4e03ba0b40a7c6470964","permalink":"https://ai4network.github.io/zh/author/%E6%9D%8E%E5%BF%97%E5%BC%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%9D%8E%E5%BF%97%E5%BC%BA/","section":"authors","summary":"","tags":null,"title":"李志强","type":"authors"},{"authors":["王韬"],"categories":null,"content":"现就职单位:三一重卡\n在校经历:发表学术论文两篇，获得专利授权两项，承担装发预研项目一项。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"d38f29c286c276d921a0a20d78aded97","permalink":"https://ai4network.github.io/zh/author/%E7%8E%8B%E9%9F%AC/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E7%8E%8B%E9%9F%AC/","section":"authors","summary":"现就职单位:三一重卡\n在校经历:发表学术论文两篇，获得专利授权两项，承担装发预研项目一项。","tags":null,"title":"王韬","type":"authors"},{"authors":["阳溯清"],"categories":null,"content":"阳溯清，国防科技大学直博生。2019年考入重庆交通大学计算机科学与技术专业，2023年推免为国防科技大学计算机科学与技术专业2023级直博生。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"dbc521cedc1e9052e98dac8bc2dfe390","permalink":"https://ai4network.github.io/zh/author/%E9%98%B3%E6%BA%AF%E6%B8%85/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%98%B3%E6%BA%AF%E6%B8%85/","section":"authors","summary":"阳溯清，国防科技大学直博生。2019年考入重庆交通大学计算机科学与技术专业，2023年推免为国防科技大学计算机科学与技术专业2023级直博生。","tags":null,"title":"阳溯清","type":"authors"},{"authors":["赵娜"],"categories":null,"content":"[1]N. Zhao, B. Han, Y. Cai, and J. Su, “Seqad: An unsupervised and sequential autoencoder ensembles based anomaly detection framework for kpi,” in 2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS). IEEE, 2021, pp. 1–6.\n[2]赵娜, 苏金树, 赵宝康, 韩彪, \u0026amp; 邹鸿程. (2022). 匿名通信系统隐藏服务定位技术研究综述. 计算机学报, 45(2), 393-411.\n[3]已授权发明专利1项\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"82a888f8dd3dc515574e595c4e628b69","permalink":"https://ai4network.github.io/zh/author/%E8%B5%B5%E5%A8%9C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E8%B5%B5%E5%A8%9C/","section":"authors","summary":"[1]N. Zhao, B. Han, Y. Cai, and J. Su, “Seqad: An unsupervised and sequential autoencoder ensembles based anomaly detection framework for kpi,” in 2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS).","tags":null,"title":"赵娜","type":"authors"},{"authors":["宋丛溪"],"categories":["Work Share"],"content":" 近年来，无人机凭借其灵活操控、视角广阔、移动性强等优势，被广泛应用于大型赛事直播、应急救援、目标识别等领域。然而，由于无人机飞行高速移动过程中带来网络质量频繁波动，尤其是采用基站入网方式的无人机在飞行过程中需要频繁切换入网点，往往无法满足高清视频传输所需的高带宽、低时延、小抖动等传输需求，更无法针对特殊应用提供定制化的服务质量（QoS）和用户体验（QoE）。\n为此，AI4Network研究团队将多路径技术引入无人机实时视频传输过程，开发研制了智能多路径无人机实时视频传输系统Smart-Flycast，旨在通过增加无人机平台的网络链路数量，提供视频传输的带宽聚合与并行传输能力，提升传输稳定性和可靠性。该系统的核心特性是智能跨层传输协议，集成典型流媒体传输协议集，底层可灵活适配多种传输协议，并支持自研的传输算法库，可实现应用协议、传输协议、控制决策算法三个层次的传输方案集成创新，增强了无人机流媒体传输在动态网络环境中的自适应能力，以及面向多种视频应用需求的可扩展性。\n目前，基于Smart-Flycast的研究工作已被网络领域国际顶级杂志IEEE Network Magazine（影响因子9.3）录用[1]。该工作结合“AI for Network”思路，通过智能算法的自适应能力辅助多路径报文调度和传输控制，为研究使能网络的人工智能技术提供了新的思路和应用场景。IEEE Network是网络领域知名刊物，专注于网络通信领域的重要问题和发展趋势。该工作作者为2020级博士研究生宋丛溪（第一作者）、2023级博士研究生计晓岚、2020级硕士研究生李亚辉、指导老师为韩彪副研究员、苏金树研究员。\n一、Smart-Flycast演示视频 视频地址\n二、Smart-Flycast系统架构 图 1 Smart-Flycast系统架构 Smart-Flycast系统架构如图1所示，包括载有摄像头和机载计算机的无人机、接收和转发实时流的云服务器以及客户端视频播放器。其中机载计算机部署了智能跨层传输协议栈。端到端的实时流媒体传输过程包括以下步骤:\n首先，传输模块从机载摄像头获取视频流并通过多个网卡（如WiFi、4G和5G）将其分发到云服务器。而后，云服务器汇聚并转发实时流。在客户端，订阅者通过视频播放器从云服务器拉取实时视频进行观看。Smart-Flycast系统的核心设计为智能跨层传输协议。\n三、智能跨层传输协议 智能跨层传输协议分为三个层次，集成了流媒体传输协议集、底层可灵活适配多种传输协议，并支持自研的传输算法库，可实现应用层协议、传输层协议、传输决策算法三种层次的传输方案组合，增强了无人机流媒体传输在动态网络环境中的自适应能力，以及面向多种视频应用需求的可扩展性。如图2所示，应用层的流媒体传输协议集支持多种流媒体传输协议，包括RTMP、RTSP和RTP；传输层支持TCP、QUIC以及多路径扩展MPTCP、MPQUIC，可根据视频传输需求跨层适配协议；传输层内置了传输算法库，支持报文调度算法RR、minRTT、ECF、BLEST、RDDT、DRAMA等，拥塞控制算法CUBIC、Olia、BBR等，可根据网络状态切换传输策略。在此基础上，开发并部署了智能算法驱动的三种传输策略，分别是基于决策树的自适应多路径报文调度DRAMA、面向QoS的自适应多路径拥塞控制ACCeSS[2]、视频内容感知的部分可靠传输算法VICTOR[3]。\n图 2 智能跨层传输协议 （1）基于决策树的自适应多路径报文调度\n异构链路以及无人机飞行期间的网络波动会导致路径状态的差异性增大，MPTCP和MPQUIC的默认报文调度器会产生不合理的决策，导致报文乱序到达从而降低应用的QoS和QoE。为了解决这个问题，使用决策树模型根据网络条件选择适合当前状态的策略。三个子策略包括，“分发”，“复制”和“丢弃”。“分发”策略根据网络状态计算每条路径的报文分配量，使报文尽可能按序到达接收端；“复制”策略将高优先级的报文复制发送到所有路径以保持传输可靠性。“丢弃”策略会主动丢弃低优先级数据的报文，以提供给高优先级报文充足带宽。\n（2）面向QoS的自适应多路径拥塞控制\n为了满足在无人机动态网络环境的多种QoS，ACCeSS面向吞吐量、丢包以及延迟三种QoS设计效用函数，针对每种类型的QoS要求，ACCeSS求解一个特定QoS的最优问题。ACCeSS包含在线速率控制和离线训练两部分。在线速率控制部分获取网络状态作为效用函数的输入，采用基于梯度的在线学习方法从效用值决定发送速率。同时，网络状态和QoS需求被输入到离线训练部分，从而根据特定QoS类型解决特定的最优问题。ACCeSS采用轻量化的随机森林回归拟合吞吐量、丢包率、延迟和发送速率之间的回归关系，预测性能指标，实现在网络波动的情况下的高效预测。\n（3）视频内容感知的部分可靠传输机制\n实时流媒体传输是一时延敏感型应用，在某些情况下，完全可靠传输带来的大量重传可能会恶化传输时延从而造成视频的卡顿。因此，我们实现了视频内容感知的部分可靠传输机制VICTOR，减少低优先级数据的重传，从而提高实时流媒体的QoE。VICTOR中实现了不可靠的流类型。在不可靠流上丢失的数据包将被丢弃，并在数据被提交到应用时，用零值填充相应的数据。根据感知到的优先级信息，流媒体内容将被区分发送到可靠和不可靠流传输。\n四、平台实现 图 3 Smart-Flycast硬件平台 Smart-Flycast的硬件平台实现如图3所示，平台载体是一架定制Dji四旋翼无人机，该平台配备了Manifold 2机载计算机，其CPU为Intel Corei7-8550U，内存为8GB RAM。实时流媒体画面通过机载高清摄像头收集。无人机通过多个网卡将流媒体传输到云服务器，网卡分别为华为8372 4G模组，以及华为MH5000 5G模组。\n五、总结与展望 Smart-Flycast无人机实时视频传输平台基于多路径传输技术，集成了跨应用层、传输层的协议以及传输算法，提升了无人机流媒体传输的实时性、可靠性与自适应能力。如今，智能技术使能网络是一个发展趋势，在诸多机器学习与智能算法中，强化学习被广泛应用于传输控制，已有研究工作将强化学习应用于拥塞控制、调度、路由优化等决策，以增强传输在多种网络状态中的自适应能力[4]。然而，基于智能的无人机传输决策仍面临亟待解决的挑战：一是智能算法的推理开销会加大无人机能耗，从而影响无人机的续航能力；二是无人机飞行导致网络状态的快速波动，智能算法在面临未知网络状态时，可能会产生输出的不可解释从而作出错误决策，进而影响无人机的任务执行。Smart-Flycast系统集成的三种智能传输算法以轻量的智能算法解决了无人机传输在高动态网络环境的挑战，并可支持多种QoS、QoE需求的挑战。作为一种智能技术使能的原型系统, Smart-Flycast通过引入多路径技术提升了传输的可靠性和稳定性，同时弥补了多路径协议缺乏自适应传输能力的短板，将为无人机实时视频传输提供更多的可能性。\n参考文献 [1] Song C, Han B, Ji X et al. AI-driven Multipath Transmission: Empowering UAV-based Live Streaming.IEEE Network, 2023. [2] Ji X, Han B, Li R, et al. ACCeSS: Adaptive QoS-aware Congestion Control for Multipath TCP[A]. 2022 IEEE/ACM 30th International Symposium on Quality of Service, IWQoS 2022[C]. 2022. [3] Li Y, Han B, Han X, et al. VICTOR: Video Content-aware Partially Reliable Transmission over Multipath QUIC. IEEE International Conference on Metaverse Computing, Networking and Applications (IEEE MetaCom 2023) 2023[c]. [4]Song C, Han B and Su J. 4D-MAP: Multipath Adaptive Packet Scheduling for Live Streaming over QUIC . Comput. Sci. Technol.\n","date":1696647165,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1696647165,"objectID":"212a225ee6f09331a4d9420a830c7876","permalink":"https://ai4network.github.io/zh/event/work-sharing-3/","publishdate":"2023-10-07T10:52:45+08:00","relpermalink":"/zh/event/work-sharing-3/","section":"event","summary":" 近年来，无人机凭借其灵活操控、视角广阔、移动性强等优势，被广泛应用于大型赛事直播、应急救援、目标识别等领域。然而，由于无人机飞行高速移动过程中带来网络质量频繁波动，尤其是采用基站入网方式的无人机在飞行过程中需要频繁切换入网点，往往无法满足高清视频传输所需的高带宽、低时延、小抖动等传输需求，更无法针对特殊应用提供定制化的服务质量（QoS）和用户体验（QoE）。\n","tags":["working sharing","宋丛溪"],"title":"Smart-Flycast：基于无人机平台的多路径实时视频传输系统","type":"event"},{"authors":["韩雪强"],"categories":["Work Share"],"content":" 近年来，随着实时流媒体等应用种类和数量的增多，流媒体应用对网络带宽、传输稳定性、用户体验的需求不断提升，仅仅依靠TCP协议难以满足高清流媒体传输的个性化服务质量需求。此外，随着网络接入技术的不断发展，终端设备具备WiFi、4G、5G等多种入网手段，流媒体传输性能受制于底层单路径、单一网络传输协议所提供的网络服务，难以在复杂多变的的动态网络环境下提供高质量可靠传输。\n为此，AI4Network团队自主研发了多路径流媒体传输加速器原型系统——“星云”，该系统可广泛部署于普通端系统设备，仅需配备多张无线网卡(Wifi/4G/5G等)，即可提供高清流媒体、实时流媒体等应用所需的多路径带宽聚合性能和用户体验优化,无额外硬件开销，便捷易用。系统内置TCP/QUIC/MPTCP/MPQUIC等多种网络传输协议，提供灵活的传输协议定制选择功能，核心技术包括自主研发的智能多路径报文调度算法和拥塞控制算法。\n“星云”演示视频 “星云”演示视频\n下面是一段“星云”系统的演示视频。客户端配备有一张WiFi网卡和一张4G网卡。我们选择公开的8K视频数据集3D_Mark _Night Raid，视频总时长4分钟，视频帧率60fps。通过测试分析，相比于传统单路径的流媒体播放器，多路径加速后带宽提升了近1倍，端到端延时降低约30%。系统演示了基于TCP(左上)、QUIC(右上)、带有缓冲区膨胀缓解功能(bufferbloat-mitigation)的多路径QUIC(左下)以及我们自主研发的多智能体多路径QUIC(右下)等协议的流媒体传输效果。可以看到，集成基于多智能体的多路径智能调度算法(MARS)的多路径QUIC协议，具有更高的聚合吞吐率，视频播放的卡顿率更低，提供了比其它传输协议更优的用户体验。\n您的浏览器不支持 video 标签 “星云”系统简介 图1 “星云”系统部署架构 “星云”系统架构如图1所示。其中硬件组成包括：多个(Wi-Fi/4G)无线网卡。软件系统包括：TCP、QUIC、MPTCP、MPQUIC等传输协议，智能报文调度算法、Web播放器前端。\n“星云”客户端部署在具有多张网卡的端设备上，Web播放器前端提供解码视频以及自适应码率调整(ABR)功能。客户端底层传输协议是一个集成多种传输协议的智能化定制传输协议栈。\n“星云”服务端是一个云视频服务器，通过单个网卡向外提供http服务，具有解析http请求并发出响应的能力。对于底层传输层协议，服务端部署有单路径TCP、QUIC以及多路径TCP和多路径QUIC，并且多路径传输协议配备有自主设计的智能多路径报文调度器和拥塞控制算法。\n当用户通过播放器前端发起浏览视频请求后，云视频服务器端能够根据网络状态以及应用的类型智能地切换和调整不同网络传输协议，并告知客户端，然后与客户端建立适应当前网络状态的传输连接。通过这样的方式，该系统实现传输定制，为用户提供更好的视频流体验质量。\n图2 “星云”系统的智能多路径报文调度算法—MARS 我们设计了基于多智能体的多路径智能调度算法，通过智能感知网络状态，获取路径的特征以及网络状态的实时变化，从而让智能算法学习网络状态进行决策。这一决策过程是具有自适应能力以及根据网络状态动态变化能力的。同时算法克服了唯一的智能体为所有的路径提供决策，导致随着路径的增加，学习难度越大的问题，使用多智能体强化学习框架，每条路径看作一个智能体，根据自己的观测进行独立决策，产生更优的决策。另外，调度过程是面向多维服务质量指标的，利用深度强化学习算法从状态中获取信息，面向多维服务质量设计的奖励函数训练，在此基础上作出最优决策。\n多路径传输协议背景介绍 多路径传输协议允许单个连接同时利用多条网络链路，具有带宽聚合和提升传输稳定性等优势。多路径TCP协议(MPTCP)在2013年IETF工作组标准化。然而，MPTCP更新需重新编译操作系统内核，阻碍了其大规模部署。近年来，快速UDP网络连接(Quick UDP Internet Connection, QUIC)协议快速发展，其多路径扩展——多路径QUIC协议(MPQUIC)，作为MPTCP的替代方案被提出。MPQUIC作为一种用户空间协议，可以持续快速升级。\nQUIC是新型传输层协议，提供具有加密、多流复用、低延迟等特点的数据传输，通过多流复用解决队头堵塞问题，通过0-RTT握手降低传输层握手时延，通过连接迁移为移动性提供更好的支持，通过在用户态实现提供了更好的可扩展性以及部署便捷性，理论上拥有比TCP更好的性能。实际上由于网络环境和设备终端的多样性，以及互联网中存在的各种攻击和各种版本的实现，QUIC在实际网络中的表现并没有达到预期。\n基于QUIC的多路径传输协议可以利用终端的多种网络接口，聚合多条物理链路，从而提高聚合带宽和传输稳定性。基于QUIC的多路径协议中的路径概念与MPTCP的子流概念类似，在握手阶段，客户端与服务端会先在一条路径上建立QUIC连接，之后每当有新的网络链路需要使用，便添加一个新的路径。基于QUIC的多路径传输设计在概念上超越了MPTCP，它提供了细粒度的流到路径调度，减少了队头阻塞，并且可以更快地建立子流，但在实际应用上缺乏成熟稳定的设计以及大规模的实验验证。\n参考文献 [1] J. Iyengar and M. Thomson, “QUIC: A UDP-Based Multiplexed and Secure Transport,” RFC 9000, May 2021. [Online]. Available: https://www.rfc-editor.org/info/rfc9000 [2] A. Ford, C. Raiciu, M. Handley, and O. Bonaventure, “TCP extensions for multipath operation with multiple addresses,” Tech. Rep., 2013. [3] Q. De Coninck and O. Bonaventure, “Multipath quic: Design and evaluation,” in Proceedings of the 13th international conference on emerging networking experiments and technologies, 2017, pp. 160–166. [4] Han X, Han B, Li R, et al. MARS: An Adaptive Multi-Agent DRL-based Scheduler for Multipath QUIC in Dynamic Networks, 2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS). IEEE, 2023, accepted. [5] Ji X, Han B, Li R, et al. ACCeSS: Adaptive QoS-aware Congestion Control for Multipath TCP[C]//2022 IEEE/ACM 30th International Symposium on Quality of Service (IWQoS). IEEE, 2022: 1-10. [6] Taraghi B, Amirpour H, Timmerer C. Multi-codec ultra high definition 8k mpeg-dash dataset[C]//Proceedings of the 13th ACM Multimedia Systems Conference. 2022: 216-220. [7] Ferlin-Oliveira S, Dreibholz T, Alay Ö. Tackling the challenge of bufferbloat in multi-path transport over heterogeneous wireless networks[C]//2014 IEEE 22nd International Symposium of Quality of Service (IWQoS). IEEE, 2014: 123-128.\n","date":1684914765,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1684914765,"objectID":"49657c311f72d4e6a3fd5915fb7e5bc7","permalink":"https://ai4network.github.io/zh/event/work-sharing-2/","publishdate":"2023-05-24T15:52:45+08:00","relpermalink":"/zh/event/work-sharing-2/","section":"event","summary":" 近年来，随着实时流媒体等应用种类和数量的增多，流媒体应用对网络带宽、传输稳定性、用户体验的需求不断提升，仅仅依靠TCP协议难以满足高清流媒体传输的个性化服务质量需求。此外，随着网络接入技术的不断发展，终端设备具备WiFi、4G、5G等多种入网手段，流媒体传输性能受制于底层单路径、单一网络传输协议所提供的网络服务，难以在复杂多变的的动态网络环境下提供高质量可靠传输。\n","tags":["working sharing","韩雪强"],"title":"AI4Network团队发布多路径流媒体传输加速器“星云”","type":"event"},{"authors":["韩雪强"],"categories":["Work Share"],"content":" 近日，AI4Network团队在多路径QUIC协议智能调度方面的工作“MARS: An Efficient Multi-agent DRL-based Scheduler for Multipath QUIC in Dynamic Networks”被第31届IEEE/ACM IWQoS 2023 (IEEE/ACM International Symposium on Quality of Service)国际会议录用。IWQoS是网络领域知名国际会议，专注于网络通信的服务质量领域，涵盖所有与QoS(服务质量)相关的最新理论和实验研究工作，长期以来一直是该领域受关注较高的国际会议，属于CCF（中国计算机学会）推荐的B类国际会议，会议录用率长期保持在**20%**左右。该工作作者为2021级硕士研究生韩雪强（第一作者），2023级博士研究生计晓岚，指导老师韩彪。\n该工作聚焦解决当前多路径QUIC(MPQUIC)协议报文调度器在动态网络环境下无法满足多样化应用QoS需求的难点，提出使用多智能体强化学习框架对服务器端QUIC协议多条路径上的报文发送量进行分布式智能控制，结合多路径拥塞控制决策，在仿真和真实的动态网络环境下，实现了MPQUIC协议吞吐量、传输延迟等性能指标的明显提升，显著减少了乱序报文，降低了接收缓冲区开销。基于该工作团队已同步开发搭建了多路径QUIC协议传输系统，可支持文件、网页、视频、实时视频流、VR/AR等多种网络应用，为设计可移植高可靠的用户态多路径传输方案提供了参考思路。\n动机与背景 随着视频流媒体、虚拟现实和增强现实等应用的深入发展，应用对底层传输网络的服务质量提出了更高的要求。多路径传输协议允许单个连接同时利用多个网络链路，如WiFi和LTE。多路径TCP协议（MPTCP）在2013年IETF工作组标准化。然而，MPTCP需要操作系统支持，阻碍了其大规模部署。快速UDP网络连接(Quick UDP Internet Connection, QUIC)协议深入发展，其多路径扩展，多路径QUIC协议（MPQUIC），作为MPTCP的替代方案被提出。MPQUIC作为一种用户空间协议，可以持续快速升级。\nMPQUIC的关键问题之一是数据包调度。根据MPQUIC的大规模部署实验，其存在严重的队头阻塞问题:高延迟路径上调度的数据包到达时间晚于低延迟路径上的数据包，导致乱序数据包到达。由于队头（Head of Line, HoL）阻塞问题，接收端不得不分配较大内存来缓存乱序数据包。通过大量的预备实验分析，我们观测到接收方缓冲区的大小严重影响了MPQUIC的吞吐量性能（图1）。此外，随着实时视频流等应用的发展，应用迫切追求低延迟，而大多数的调度器仅针对特定应用需求设计。例如，基于强化学习(RL )的调度器 Peekaboo只关注最大化吞吐量，而不考虑数据包所经历的延迟。另一方面，bufferbloat-mitigation(BM)算法旨在降低缓存膨胀的影响以获得低延迟，但无法实现高吞吐量。多路径调度性能与应用需求仍有差距，如图2所示。\n图1 不同大小缓冲区下多路径调度器的吞吐量 图2 不同多路径调度器的RTT百分位分布图 设计方案 针对上述问题，该工作提出使用多智能体强化学习的方法，结合多目标奖励函数来实现在动态网络环境下对应用多样化QoS需求的动态适应。\n1.多智能体强化学习\n1）为什么使用多智能体强化学习\n从方法论的角度，我们将多路径调度视为一个决策问题，采用强化学习(RL)方法进行求解。与使用规则式策略的启发式方法不同，基于RL的调度器通过学习产生能够适应动态网络环境的数据包调度策略。之前的研究工作也考虑了将RL方法用于数据包调度问题：如Peekaboo使用在线RL算法生成调度策略，但收敛时间是在线方案的一个基本问题，并未得到很好解决；ReLeS探索了通过深度强化学习(DRL)方法来解决MPTCP中的调度问题，使用单智能体DRL为所有路径生成连接级控制策略。然而，当路径数量增加时，唯一的智能体学习最优调度策略的能力受限。因此在本工作中，我们应用多智能体强化学习(MADRL)方法对每条路径进行单独控制，以减轻单个智能体的负担，生成更优的策略。\n2）设计框架\n图3 MARS的实现框架图 MARS框架如图3所示。MARS采用了MADDPG算法，一种多智能体和演员-评论家深度强化学习算法。在MARS中，每个智能体都有一个演员和评论家神经网络。我们采用异步训练算法，将数据收集和模型训练分离，以保证实时的数据包调度。因此，MARS框架主要由在线执行和离线训练两部分组成。\n在线执行。在线执行过程中(图3右半部分)，运行在发送端(服务器)的智能体感知网络环境，获取网络状态 $O_{i,t}$。然后，智能体将它们输入到执行器神经网络，该神经网络输出动作 $∏(O_{i,t})$。深度强化学习智能体面临的一个根本性挑战是解决探索与利用的困境。为了使智能体能够更好地探索未知环境，我们在演员神经网络生成的动作中加入衰减高斯噪声，可以表示为 $a_{i,t} = ∏(O_{i,t}) + N ( 0,σ_{i,t})$。智能体执行动作并得到结果奖励 $r_{i，t}$，然后转移到下一个新状态 $O_{i,t+1}$。为了有效地从经验中学习，智能体在一步转移中收集状态、动作和奖励，并将它们打包成一个元组 $\u0026lt;O_{i,t}，O_{_i,t}，a_{i,t}，a_{_i,t}，r_{i,t}，O_{i,t+1}，O_{i,t+1}\u0026gt;$，并将元组存储到经验回放缓冲区$D_i$中。\n离线训练。在离线训练过程中(图3左图部分)，智能体从经验回放缓冲区中采样，然后使用深度确定性策略梯度训练算法训练演员和评论家神经网络。每次训练后，MARS将训练好的演员神经网络与调度器进行同步，使其向最优策略移动。\n2.多目标奖励函数设计\n考虑具有n条路径(记N = { 1 , … , n })的多路径传输协议。它的网络资源有限，包括缓冲区和数据包等。这些资源被路径共享。在MARS中，每条路径都有一个带着独立奖励函数的深度强化学习智能体。对于传统的单智能体深度强化学习智能体，它自私地最大化自身奖励。但在MARS中，如果所有的智能体简单地最大化自己的奖励，并不能使多路径传输协议获得最大的性能。因此，我们将多路径传输协议调度问题看成一个一般和的n人博弈，其中每个智能体是一个玩家。我们通过设计利他奖励项，将利他行为引入到每个智能体中。这说明智能体并不是单纯最大化自身的性能，还关心其他路径的性能。它们相互竞争资源，同时为了获得更好的性能，它们合作将所有的数据传输到接收端。此外，在奖励函数的设计中，我们考虑了吞吐量、时延和乱序队列大小。智能体i的奖励函数记为：\n$$ r_{i,t} = V^{th}-\\beta V^{RTT} - \\zeta V^{OFO} $$ 实验验证 图4 网络拓扑图 仿真实验采用如图4所示的网络拓扑结构。对于两条路径，我们分别设定了根据真实实验中的测量值选择的具体网络特征。采用32MB的文件下载应用程序进行性能评估。每个实验重复了20次。\n1.不同接收方缓冲区下的吞吐表现\n图5展示了不同调度器在不同接收缓存大小下的聚合吞吐量。当接收缓存大小受限(\u0026lt;3MB)时，我们的调度器相比RR可以提高约16 %的吞吐量。当接收缓存足够大(≥3MB)时，没有HoL阻塞，因此6个调度器都能获得较好的带宽聚合效果。但是MARS的表现仍然优于其它调度器。\n图5 不同调度器在不同接收缓存大小下的聚合吞吐量 2.减少乱序数据包\n我们使用乱序（OFO）队列大小作为度量。OFO队列规模越大，调度器性能越差。图 6给出了不同接收缓冲区大小下不同调度器的平均OFO队列大小。其他调度器在接收缓冲区大小有限的情况下可以保持较小的OFO队列大小，但随着接收缓冲区大小的增加，OFO 队列大小急剧增加。而MARS可以保持非常小的 OFO 队列大小，并且由于OFO队列大小的反馈，受接收缓冲区大小的影响较小。\n图6 不同接收缓冲区大小下不同调度器的平均OFO队列大小 3.降低传输延迟\n图7给出了RTT的百分位分布。从图7中我们可以观察到MARS比其他调度器实现了更小的RTT。这是因为与BM算法相比，MARS算法根据当前网络状态更加智能地做出决策，以降低数据包排队时延。同时，MARS充分利用快速路径来满足应用的低延迟需求。\n图7 RTT的百分位分布图 4.真实网络环境下的性能表现\n通过评估不同调度器的下载时间来研究MARS在异构网络中的性能。我们 通过改变下载大小来模拟不同的流量类型。对于2MB的下载文件大小，MARS实现了与 Peekaboo相近的下载时间，但是与其他调度器相比，下载时间最低。然而，随着下载文件大小越来越大，MARS的优势更加明显。\n图8 真实网络环境下不同调度器的文件下载时间 总结 本工作提出了一种基于多智能体强化学习的 MPQUIC调度器 MARS，为适应不同接收端缓存大小和不同应用的QoS需求，MARS利用多智能体强化学习（MADRL） 技术在每条路径上独立生成数据包调度策略。同时，我们设计了一个多目标奖励函数来表征应用程序的QoS需求和乱序队列大小对协议性能的影响。我们在仿真和真实环境下评估了MARS，结果表明MARS的性能表现显著优于现有的多路径调度器。\n该工作的源代码和原型系统将于近期发布，敬请关注。\n","date":1680597755,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1680597755,"objectID":"4c36448c18c8ba1dc3c62fda7063cb07","permalink":"https://ai4network.github.io/zh/event/work-sharing-1/","publishdate":"2023-04-04T16:42:35+08:00","relpermalink":"/zh/event/work-sharing-1/","section":"event","summary":" 近日，AI4Network团队在多路径QUIC协议智能调度方面的工作“MARS: An Efficient Multi-agent DRL-based Scheduler for Multipath QUIC in Dynamic Networks”被第31届IEEE/ACM IWQoS 2023 (IEEE/ACM International Symposium on Quality of Service)国际会议录用。IWQoS是网络领域知名国际会议，专注于网络通信的服务质量领域，涵盖所有与QoS(服务质量)相关的最新理论和实验研究工作，长期以来一直是该领域受关注较高的国际会议，属于CCF（中国计算机学会）推荐的B类国际会议，会议录用率长期保持在**20%**左右。该工作作者为2021级硕士研究生韩雪强（第一作者），2023级博士研究生计晓岚，指导老师韩彪。\n","tags":["working sharing","IWQoS2023","韩雪强"],"title":"AI4Network团队在智能多路径QUIC协议方向工作被国际会议IEEE IWQoS2023录用","type":"event"},{"authors":["宋丛溪","计晓岚"],"categories":null,"content":"腾讯会议：840-471-729\n会议密码：16092\n","date":1680291000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1680291000,"objectID":"4b584e3e35d4d8afebf5234acf3e0500","permalink":"https://ai4network.github.io/zh/event/8/","publishdate":"2023-03-31T19:30:00Z","relpermalink":"/zh/event/8/","section":"event","summary":"腾讯会议：840-471-729\n会议密码：16092","tags":[],"title":"2023年秋季学期第7周组会","type":"event"},{"authors":["黄鑫"],"categories":["Paper Share"],"content":" 本次分享的是来自SIGCOMM22可编程数据平面的一篇论文：Predictable vFabric on Informative Data Plane，该文作者来自清华大学，阿里巴巴和剑桥大学。\n背景 在多租户数据中心中，租户的虚拟机（VM）希望通过虚拟网络结构（VF）进行逻辑互连，就像在一个专门的集群中一样，尽管所有租户共享同一个物理网络。虽然已经提出了许多解决方案来提高多租户数据中心网络（DCN）的性能，它们不能胜任提供强烈的可预测的VF服务–带宽保证、带宽利用和确定性尾部延迟，其主要因为以下两个原因。\n首先，先前可预测的VF工作的收敛速度（几十毫秒）未能赶上当今应用的日益严格的性能要求。例如，作为弹性块存储中最高性能级别的磁盘，增强型固态硬盘要求I/O操作延迟平均为100μs，尾部延迟为1ms。另一方面，随着专业计算加速器的出现，分布式计算应用（如分布式机器学习）的性能瓶颈正在从计算转向通信；因此，每次参数/激活传输开始时，它们都需要即时可用的带宽，尤其是分布式机器学习推理，通常涉及多次传输，需要在10ms内响应在线查询。因此，快速处理流量动态，即在亚毫秒级的时间尺度上，对于满足当今应用的性能需求至关重要。\n其次，端到端的带宽保证很容易被与保证无关的路径管理方案破坏。现有的解决方案在提供带宽保证的同时，还考虑到带宽利用，大多将网络结构视为源和目的地之间的聚合管道，假设具体的路径选择是由互补的负载平衡方案做出的，例如，选择随机路径或利用率最低的路径。然而，由于带宽利用，链路利用率（实际流量）和链路订阅（有带宽保证的流量）并不等同。当一个具有高流量需求的新流量进入网络时，将其分配到利用率最低的路径可能会违反其他路径的带宽保证。因此，这个路径上的所有流量都会收敛到低于其带宽保证的新速率，并面临显著的性能下降。\n针对以上问题，阿里巴巴提出μFAB，一个为数据中心租户提供高度可预测的VF服务的框架，μFAB揭示了端网协同的融合设计，利用可编程网络提供的精细网络信息，在端上智能网卡用于速率控制和路径选择。这些设计的部署，极大地提升了网络传输的服务质量，也给云上客户以及未来算力融合带来了持续价值。\n设计方案 （1）层次化的带宽分配。首先，边缘为每个流量选择一个路径，以保持总的有效带宽订阅，即通过链路的租户的最小带宽保证之和，不超过链路容量。因此，如果链路容量被流量按比例分享给它们的最小带宽，那么所有租户的最小带宽都能得到保证。然后，边缘迅速而准确地调整发送速率，使带宽利用率收敛到目标值。因此，即使一些租户的需求不足，未使用的带宽也可以被共享同一链路的其他租户迅速利用；反之，如果一个租户有即时的流量需求，它可以迅速抢回其保证的带宽。我们的理论分析表明，μFAB可以同时实现严格保证的最小带宽和高网络利用率。\n（2）两阶段和基于窗口的流量接纳。为了避免排队，每个边缘使用一个由带宽利用率更新的窗口，即基于利用率的窗口，来限制租户在路径上的飞行流量。在整个主机中，μFAB控制每个租户的总突发量，直到他们的最小带宽保证，并加法增加他们的发送窗口，直到基于利用率的窗口斜率下降，并开始使用后者。因此，μFAB可以将瓶颈链路上的队列大小约束为BDP（带宽-延迟乘积）的三倍。\n（3）精准和稳定的路径迁移。μFAB通过一个探针对可用带宽和路径上的延迟峰值风险作出及时和准确的判断，而不是真的把流量放在路径上。因此，边缘可以迅速选择一个适当的路径来迁移，以保持端到端的性能，而不需要漫长的收敛过程或影响其他无辜的租户；μFAB的路径迁移还可以避免振荡和数据包重新排序。\nμFAB服务模型 µFAB的目标，是在云数据中心为租户提供带宽保障、低延迟保障，以及最大化利用网络带宽资源。但在目前的网络架构中，要同时实现这三点是非常困难，主要原因是：之前的工作通常把网络当作一个黑盒，利用时延、探测等一系列的启发式算法来做速率控制和路径选择，这样便造成了需要毫秒级别的收敛时间，难以满足应用日渐增加的对于性能的需求。\nµFAB的设计理念则恰好相反，其核心思想是网络的透明化和信息化，即利用可编程网络数据平面提供的链路状态和租户信息，并将这些信息反馈到主机侧用于智能的速率控制和路径选择。\n上图所示µFAB的服务模型，每个租户会被分配一个虚拟的网络（Virtual Fabric），该虚拟网络为租户提供最小带宽保障、最大化利用资源、低长尾延迟等三个SLA保障。而租户的最小带宽分配遵循云的弹性部署规范，租户总带宽之和不会超过网络物理总带宽。µFAB利用可编程网络提供的精确信息，再通过端网协同的机制达到上述目标。\n端网协同的具体工作方式为：一方面，主机侧的µFAB-E模块发送探测包，用以获取网络的信息，从而指导其做“速率控制”和“路径选择”。另一方面，网络交换机上的µFAB-C模块收集链路状态和租户的信息，并将这些信息做聚合，插入到发过来的探测包中，反馈给µFAB-E。\n上图为μFAB的工作流程：每个\u0026#34;μFAB-E\u0026#34;沿每个活动的底层路径发送探针（步骤1）。探针到达一个μFAB-C后，μFAB-C首先读取捎带的VF信息，并将其与内部VF信息汇总（步骤2），然后将更新的结果插入探针（步骤3）。接下来，探针沿着路径转发，直到到达目的地（步骤4）。当目的地μFAB-E发送的响应回来时（步骤5），源μFAB-E将决定是否继续使用该路径，并根据响应中提供的信息进行速率调整，或者在当前路径不再合格时开始迁移到其他路径（步骤6）。\n带宽延迟保障算法 有了网络透明化和端网协同，如何才能做到带宽和时延的保障呢？\nµFAB使用的是按权重分配的做法，这样做的好处是可以很快判断出带宽是否得到了满足。发送窗口的计算方法为：\n$$ w = \\frac{\\phi}{\\sum\\phi} \\times \\sum w \\times \\frac{C \\times RTT}{tx \\times RTT + q_{lean}} $$ 其中，φ/∑φ是按租户的权重进行的按权分配，而 ∑w是交换机维护的所有租户的发送窗口之和，(C*RTT)/(tx*RTT+qlean)则是根据链路的负载进行的调整，用于最大化链路利用，同时做拥塞避免。φ、w由探测包携带到网络交换机中，∑φ、∑w由交换机维护的租户信息的聚合，而tx、qlen是交换机维护的网络链路信息。\n当多个租户同时有流量请求的时候，μFAB允许租户无论何时都可以按照最小带宽保障发送，只有在网络有剩余带宽的情况下，才会逐渐增大发送速率。这么做的原理是，最小带宽是租户的SLA保障必须满足，而尽可能地提高发送速率则是额外的奖励，时效性要求相对较低。这样既满足了租户对于随时获取最小带宽的承诺，又使得在有多租户突发流量的冲突的时候，依然能够保障网络的长尾时延。\n另一个重要的点是，µFAB能够充分利用整个网络的带宽资源，当一个路径上的带宽资源已经被分配完时，能够快速地进行路径切换，从而使用多个路径的网络带宽资源。在路径切换时，需要考虑两种场景：一是当前路径的带宽已经不满足租户SLA，这种情况需要立刻进行路径切换，但也要注意不要过于频繁地连续切换。二是发现有路径的更多带宽资源的时候，这种情况的路径切换是一种最大化利用网络资源的行为，但相对来说没有紧迫的时间需求，因此不用做得过于频繁。\n硬件实验 实验团队分别在基于FPGA和SOC的硬件网卡和Tofino交换机上做了相应的算法实现，并在三层fat-tree的网络拓扑上做了网络层验证和应用层验证。\n实验表明，µFAB能提供给租户最小带宽保障和长尾低延迟，同时提供最大化地网络带宽利用，即使面对网络故障的场景下，依然能够快速收敛。\n为了验证µFAB对于应用的实际增益，实验团队将一个租户运行时延敏感型的Memcached，另一个租户运行大带宽的MongoDB应用进行对比实验。实验表明，µFAB能实现接近于理想状态下的QPS（Query Per Second）和QCT（Query Completion Time）。这是因为µFAB总是能正确的选择流量路径，从而实现性能的隔离，以及快速的响应网络拥塞。下图可以看出µFAB能为应用等提供2.5倍的QPS提升、21倍的长尾延迟下降。\n总结 新兴的可编程数据平面是解决在多租户 DCN 中提供可预测的虚拟结构的特殊挑战的关键——μFAB就是一个例子。该文章提出了μFAB，这是一种可预测的虚拟结构解决方案，μFAB通过活动边缘和信息核心的融合构建了可预测的VF服务，其创新在于通过简单有效的机制，可以为所有流显式选择正确的路径，并且使整个网络在亚毫秒级时间尺度上收敛到可预测的租户级性能（例如，保证带宽和有限延迟）和高利用率。\n","date":1674031355,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1674031355,"objectID":"d09d54b50c601dba12ba5477d92594d3","permalink":"https://ai4network.github.io/zh/post/paper-sharing-11/","publishdate":"2023-01-18T16:42:35+08:00","relpermalink":"/zh/post/paper-sharing-11/","section":"post","summary":" 本次分享的是来自SIGCOMM22可编程数据平面的一篇论文：Predictable vFabric on Informative Data Plane，该文作者来自清华大学，阿里巴巴和剑桥大学。\n","tags":["paper sharing","SIGCOMM22","黄鑫"],"title":"SIGCOMM22 论文分享 | Predictable vFabric on Informative Data Plane","type":"post"},{"authors":["黄鑫"],"categories":["Paper Share"],"content":" 本次分享的是来自SIGCOMM22可编程数据平面的一篇论文：Predictable vFabric on Informative Data Plane，该文作者来自清华大学，阿里巴巴和剑桥大学。\n背景 在多租户数据中心中，租户的虚拟机（VM）希望通过虚拟网络结构（VF）进行逻辑互连，就像在一个专门的集群中一样，尽管所有租户共享同一个物理网络。虽然已经提出了许多解决方案来提高多租户数据中心网络（DCN）的性能，它们不能胜任提供强烈的可预测的VF服务–带宽保证、带宽利用和确定性尾部延迟，其主要因为以下两个原因。\n首先，先前可预测的VF工作的收敛速度（几十毫秒）未能赶上当今应用的日益严格的性能要求。例如，作为弹性块存储中最高性能级别的磁盘，增强型固态硬盘要求I/O操作延迟平均为100μs，尾部延迟为1ms。另一方面，随着专业计算加速器的出现，分布式计算应用（如分布式机器学习）的性能瓶颈正在从计算转向通信；因此，每次参数/激活传输开始时，它们都需要即时可用的带宽，尤其是分布式机器学习推理，通常涉及多次传输，需要在10ms内响应在线查询。因此，快速处理流量动态，即在亚毫秒级的时间尺度上，对于满足当今应用的性能需求至关重要。\n其次，端到端的带宽保证很容易被与保证无关的路径管理方案破坏。现有的解决方案在提供带宽保证的同时，还考虑到带宽利用，大多将网络结构视为源和目的地之间的聚合管道，假设具体的路径选择是由互补的负载平衡方案做出的，例如，选择随机路径或利用率最低的路径。然而，由于带宽利用，链路利用率（实际流量）和链路订阅（有带宽保证的流量）并不等同。当一个具有高流量需求的新流量进入网络时，将其分配到利用率最低的路径可能会违反其他路径的带宽保证。因此，这个路径上的所有流量都会收敛到低于其带宽保证的新速率，并面临显著的性能下降。\n针对以上问题，阿里巴巴提出μFAB，一个为数据中心租户提供高度可预测的VF服务的框架，μFAB揭示了端网协同的融合设计，利用可编程网络提供的精细网络信息，在端上智能网卡用于速率控制和路径选择。这些设计的部署，极大地提升了网络传输的服务质量，也给云上客户以及未来算力融合带来了持续价值。\n设计方案 （1）层次化的带宽分配。首先，边缘为每个流量选择一个路径，以保持总的有效带宽订阅，即通过链路的租户的最小带宽保证之和，不超过链路容量。因此，如果链路容量被流量按比例分享给它们的最小带宽，那么所有租户的最小带宽都能得到保证。然后，边缘迅速而准确地调整发送速率，使带宽利用率收敛到目标值。因此，即使一些租户的需求不足，未使用的带宽也可以被共享同一链路的其他租户迅速利用；反之，如果一个租户有即时的流量需求，它可以迅速抢回其保证的带宽。我们的理论分析表明，μFAB可以同时实现严格保证的最小带宽和高网络利用率。\n（2）两阶段和基于窗口的流量接纳。为了避免排队，每个边缘使用一个由带宽利用率更新的窗口，即基于利用率的窗口，来限制租户在路径上的飞行流量。在整个主机中，μFAB控制每个租户的总突发量，直到他们的最小带宽保证，并加法增加他们的发送窗口，直到基于利用率的窗口斜率下降，并开始使用后者。因此，μFAB可以将瓶颈链路上的队列大小约束为BDP（带宽-延迟乘积）的三倍。\n（3）精准和稳定的路径迁移。μFAB通过一个探针对可用带宽和路径上的延迟峰值风险作出及时和准确的判断，而不是真的把流量放在路径上。因此，边缘可以迅速选择一个适当的路径来迁移，以保持端到端的性能，而不需要漫长的收敛过程或影响其他无辜的租户；μFAB的路径迁移还可以避免振荡和数据包重新排序。\nμFAB服务模型 µFAB的目标，是在云数据中心为租户提供带宽保障、低延迟保障，以及最大化利用网络带宽资源。但在目前的网络架构中，要同时实现这三点是非常困难，主要原因是：之前的工作通常把网络当作一个黑盒，利用时延、探测等一系列的启发式算法来做速率控制和路径选择，这样便造成了需要毫秒级别的收敛时间，难以满足应用日渐增加的对于性能的需求。\nµFAB的设计理念则恰好相反，其核心思想是网络的透明化和信息化，即利用可编程网络数据平面提供的链路状态和租户信息，并将这些信息反馈到主机侧用于智能的速率控制和路径选择。\n上图所示µFAB的服务模型，每个租户会被分配一个虚拟的网络（Virtual Fabric），该虚拟网络为租户提供最小带宽保障、最大化利用资源、低长尾延迟等三个SLA保障。而租户的最小带宽分配遵循云的弹性部署规范，租户总带宽之和不会超过网络物理总带宽。µFAB利用可编程网络提供的精确信息，再通过端网协同的机制达到上述目标。\n端网协同的具体工作方式为：一方面，主机侧的µFAB-E模块发送探测包，用以获取网络的信息，从而指导其做“速率控制”和“路径选择”。另一方面，网络交换机上的µFAB-C模块收集链路状态和租户的信息，并将这些信息做聚合，插入到发过来的探测包中，反馈给µFAB-E。\n上图为μFAB的工作流程：每个\u0026#34;μFAB-E\u0026#34;沿每个活动的底层路径发送探针（步骤1）。探针到达一个μFAB-C后，μFAB-C首先读取捎带的VF信息，并将其与内部VF信息汇总（步骤2），然后将更新的结果插入探针（步骤3）。接下来，探针沿着路径转发，直到到达目的地（步骤4）。当目的地μFAB-E发送的响应回来时（步骤5），源μFAB-E将决定是否继续使用该路径，并根据响应中提供的信息进行速率调整，或者在当前路径不再合格时开始迁移到其他路径（步骤6）。\n带宽延迟保障算法 有了网络透明化和端网协同，如何才能做到带宽和时延的保障呢？\nµFAB使用的是按权重分配的做法，这样做的好处是可以很快判断出带宽是否得到了满足。发送窗口的计算方法为：\n$$ w = \\frac{\\phi}{\\sum\\phi} \\times \\sum w \\times \\frac{C \\times RTT}{tx \\times RTT + q_{lean}} $$ 其中，φ/∑φ是按租户的权重进行的按权分配，而 ∑w是交换机维护的所有租户的发送窗口之和，(C*RTT)/(tx*RTT+qlean)则是根据链路的负载进行的调整，用于最大化链路利用，同时做拥塞避免。φ、w由探测包携带到网络交换机中，∑φ、∑w由交换机维护的租户信息的聚合，而tx、qlen是交换机维护的网络链路信息。\n当多个租户同时有流量请求的时候，μFAB允许租户无论何时都可以按照最小带宽保障发送，只有在网络有剩余带宽的情况下，才会逐渐增大发送速率。这么做的原理是，最小带宽是租户的SLA保障必须满足，而尽可能地提高发送速率则是额外的奖励，时效性要求相对较低。这样既满足了租户对于随时获取最小带宽的承诺，又使得在有多租户突发流量的冲突的时候，依然能够保障网络的长尾时延。\n另一个重要的点是，µFAB能够充分利用整个网络的带宽资源，当一个路径上的带宽资源已经被分配完时，能够快速地进行路径切换，从而使用多个路径的网络带宽资源。在路径切换时，需要考虑两种场景：一是当前路径的带宽已经不满足租户SLA，这种情况需要立刻进行路径切换，但也要注意不要过于频繁地连续切换。二是发现有路径的更多带宽资源的时候，这种情况的路径切换是一种最大化利用网络资源的行为，但相对来说没有紧迫的时间需求，因此不用做得过于频繁。\n硬件实验 实验团队分别在基于FPGA和SOC的硬件网卡和Tofino交换机上做了相应的算法实现，并在三层fat-tree的网络拓扑上做了网络层验证和应用层验证。\n实验表明，µFAB能提供给租户最小带宽保障和长尾低延迟，同时提供最大化地网络带宽利用，即使面对网络故障的场景下，依然能够快速收敛。\n为了验证µFAB对于应用的实际增益，实验团队将一个租户运行时延敏感型的Memcached，另一个租户运行大带宽的MongoDB应用进行对比实验。实验表明，µFAB能实现接近于理想状态下的QPS（Query Per Second）和QCT（Query Completion Time）。这是因为µFAB总是能正确的选择流量路径，从而实现性能的隔离，以及快速的响应网络拥塞。下图可以看出µFAB能为应用等提供2.5倍的QPS提升、21倍的长尾延迟下降。\n总结 新兴的可编程数据平面是解决在多租户 DCN 中提供可预测的虚拟结构的特殊挑战的关键——μFAB就是一个例子。该文章提出了μFAB，这是一种可预测的虚拟结构解决方案，μFAB通过活动边缘和信息核心的融合构建了可预测的VF服务，其创新在于通过简单有效的机制，可以为所有流显式选择正确的路径，并且使整个网络在亚毫秒级时间尺度上收敛到可预测的租户级性能（例如，保证带宽和有限延迟）和高利用率。\n","date":1674031355,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1674031355,"objectID":"9f11992fbf9bf84fd3b205a02fd7f958","permalink":"https://ai4network.github.io/zh/post/paper-sharing-12/","publishdate":"2023-01-18T16:42:35+08:00","relpermalink":"/zh/post/paper-sharing-12/","section":"post","summary":" 本次分享的是来自SIGCOMM22可编程数据平面的一篇论文：Predictable vFabric on Informative Data Plane，该文作者来自清华大学，阿里巴巴和剑桥大学。\n","tags":["paper sharing","SIGCOMM22","黄鑫"],"title":"SIGCOMM22 论文分享 | Predictable vFabric on Informative Data Plane","type":"post"},{"authors":["梁观平"],"categories":["Paper Share"],"content":" 今天给大家介绍的论文发表在SIGCOMM22会议上，作者团队来自宾夕法尼亚大学。本文提出了Cebinae，这是一种用惩罚超过其最大最小公平份额的流量来增强现有主机网络的公平性。Cebinae将拥塞控制算法作为黑盒，对其进行兼容，可部署在商用可编程交换机上。通过实验发现，在网络带宽分配角度，Cebinae的表现优于其他实现公平性的算法。\n研究动机 对于像互联网和云公共网络，终端主机应用程序可以使用他们希望的任何拥塞控制协议。然而不同的网络状态（RTT）和拥塞控制协议使用的不同都会导致不公平的带宽分配。因此随着时间的推移，网络的异构性也会急剧增加，从而造成更多不公平分配。\n从概念上讲，公平的排队通过将每个流分配给一个独立的队列，并以每位循环顺序为每个流提供服务。为了模拟公平的排队调度，现有方法准确性仍然需要独占使用许多优先级和对每个流的可用缓冲区数量的限制，这两个限制随着流计数、RTT和突发性的增加而变得更加严格。因此现有的解决方案仍然难以在有限的硬件资源下拓展到公共网络，作者指出困难的来源是由于现有的方法试图跟踪并调度每一个流。\nCebinae机制没有在每个时间点进行字节级或包级调度，因为这对于公平的全局收敛是过度的。网络将带宽从满足/超过其公平份额的流重新分配给不满足的流就足够了。这种简化能够以最小的资源（瓶颈和非瓶颈流二分类问题，仅需一个额外的队列优先级）对高级调度逻辑进行非常有效的近似，并大大提高了可扩展性。\n关键技术 首先本文从最大-最小公平性的角度出发，对瓶颈链路和瓶颈流的进行了判定。具体而言，如下图所示：\n每条链路都可以确定一组瓶颈流集合。首先，如果该链路不是饱和的，那么该链路上的所有流都可以继续增加其发送速率，因此它们不是瓶颈流；其次如果链路是饱和的，那么只要在该链路上发送速率最大的流便被认为是瓶颈流，这是因为发送速率最大的流占用了绝大部分带宽，通过对其进行相关处理，便可以改善不公平分配的情况；否则便不是瓶颈流。\n现有方法对于瓶颈流的处理大多采用的是限速操作，只有当链路总需求量低于自身承载能力时，限速才会被解除。然后这种原始的处理方式有一个缺点就是无法使不公平的分配变得公平，如下图所示：\n当C流在10容量的链路中获得6容量带宽时，由于只对瓶颈流C进行限速操作，ABDE便会平均分配剩余4容量的带宽，然而这样的分配并不是公平的，然后限速操作并不能让这样不公平的分配变得公平。\n不同于之前的限速操作，Cebinae直接对瓶颈流C进行征税操作，然后将征得的带宽税分配到ABDE，经过数次的征税操作之后，不公平的分配可以变得公平。下图说明了对超过公平份额的流进行征税和再分配的过程：\nCebinae每个路由器的架构如图所示：（a）正常运行期间（b）控制平面重构期间\n每个路由器包含三个组件：\n出口管道流速率缓存，它以细粒度跟踪端口饱和度和瓶颈流状态。\n入口管道流调度器，它向瓶颈流输入延迟/损失，以限制和重新分配它们的带宽。\n低延迟控制平面代理，它记录流量并动态调整瓶颈流成员度和发送速率限制。\n从图中可以看到出口处有两个探测器：端口饱和度探测器和瓶颈流探测器。\n为了准确地确定端口饱和度，Cebinae在出口管道上跟踪利用率，为每个端口维护一个简单的传输字节计数器，作为元素存储在一个寄存器数组中。Cebinae控制平面代理定期对寄存器数组进行采样，并在不重置计数器的情况下，计算与前一次迭代观察到的差异，以找到最后一个间隔期间的利用率。如果利用率高于设定值，则认为该链路已饱和。\n如果端口饱和度是正的，那么Cebinae就可以确定哪些流是当前链路的瓶颈。Cebinae通过出口管道来检测这些瓶颈流。其目标是准确地跟踪（a）最大流的大小和（b）任何相似大小的流的id。Cebinae使用了散列映射流表的多个阶段。到达一个阶段的数据包被散列到一个条目，要么增加其字节计数器（如果该条目未使用或是用于数据包的流），要么继续到下一个阶段（如果该条目已经被另一个流使用）。Cebinae查找任何流的最大字节计数器，并声明如果它们的字节计数满足约束条件，则该流为“瓶颈流”。\n实验验证 作者分别在交换机和ns3仿真中进行了实验，通过实验发现cebinae可以减轻各种网络中的不公平性。\n下图显示了对于16个TCP Vegas流(0-15)和一个NewReno流(16)，在分别使用FIFO和Cebinae在100 Mbps瓶颈链路上竞争的情况。Cebinae在几乎不影响效率的情况下，将不公平分配转向公平。\n当16个Vegas流(基于延迟)与1个NewReno流(基于损耗)在100 Mbps链路上竞争时，每个流具有相等的RTT和需求。对于FIFO，单个NewReno流占用了大约80%的带宽。Cebinae通过重新分配NewReno流的带宽并允许其余流增加其份额来提高公平性。\n图a说明了一个类似的情况，即128个NewReno流在1 Gbps链路上与2个BBR流竞争，RTT和需求相等。Cebine对BBR流要求的过度带宽征税，并将JFI从0.774提高到0.936。\n另一种情况是，128个NewReno流在1Gbps链路上与4个Vegas流竞争，其性能需求和RTT分别为100ms和64ms。虽然最初的JFI提供了看似较高的值（0.956），但这是由于大多数NewReno流量（及其主要流量）得到了相对公平的分配。这掩盖了对4个拉斯维加斯流量的不公平分配，如图b中详细的goodput分布所示。Cebinae减轻了4个Vegas流的饥饿现象。\n个人总结 Cebinae将拥塞算法视为黑盒，通过征税的的手段近似地实现了最大最小公平，解决了原始最大最小公平无法使不公平分配公平化的弊端，虽然没有从理论上证明Cebinae收敛到最大最小公平，但是它能够利用更少的资源减轻不公平现象。\n解决某类问题，可以将其映射到实际生活中，通过实际生活已有的模型或者方法对问题进行抽象。\n","date":1673336406,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1673336406,"objectID":"827108072321dd33dd3570488fc9dc9f","permalink":"https://ai4network.github.io/zh/post/paper-sharing-9/","publishdate":"2023-01-10T15:40:06+08:00","relpermalink":"/zh/post/paper-sharing-9/","section":"post","summary":" 今天给大家介绍的论文发表在SIGCOMM22会议上，作者团队来自宾夕法尼亚大学。本文提出了Cebinae，这是一种用惩罚超过其最大最小公平份额的流量来增强现有主机网络的公平性。Cebinae将拥塞控制算法作为黑盒，对其进行兼容，可部署在商用可编程交换机上。通过实验发现，在网络带宽分配角度，Cebinae的表现优于其他实现公平性的算法。\n","tags":["paper sharing","SIGCOMM22","梁观平"],"title":"SIGCOMM22 论文分享 | Cebinae: Scalable ln-network Fairness Augmentation","type":"post"},{"authors":["陈鑫"],"categories":["Paper Share"],"content":" 今天给大家介绍的论文是由Google的研究团队提出的PLB——一种建立在传输协议和ECMP/WCMP之上，用于数据中心网络以减少网络热点的链路负载平衡设计。\n一、背景介绍 当Google数据中心有未使用的容量时，拥塞热点会降低性能。热点是具有显著排队或丢包的拥塞交换机输出端口。而负载均衡问题一直都是一个值得广泛研究的问题，负载不均衡对数据中心网络的性能和效率都提出了挑战。\n作者试图缓解Google数据中心上的拥塞问题时，发现无法应用已有的负载均衡的设计方案。这些方案是昂贵且耗时的，难以进行大规模部署。作者希望有一种负载均衡策略能够增量部署，以控制成本和可靠性风险。同时适应Google机群的异构性。因此作者提出了PLB这种简单有效的机制来满足以上需求，PLB利用了ipv6协议的支持，它只需要少量的传输配置更改，并可以与我们现有的交换机一起使用。它在整个谷歌数据中心都得到了部署和应用，它实现了更好的负载均衡、更低的丢包率以及更小的应用延迟。作者也将代码进行了开源。\n目前最广泛使用的数据中心网络中跨多条路径传播流量的标准负载平衡机制是ECMP（Equal Cost Multi-Path）和WCMP（Weighted Cost Multi-Path）。当开启ECMP功能时，便可同时利用多条路径，实现基于流的负载均衡；WCMP基于路径权重，根据路径的权重分配流量，权重大的路径分配的流量更多。\n但是这样简单的机制用于数据中心也是有一些缺点的。由于数据中心流量通常是重尾的，其中少量长流贡献了所有流量的重要部分。因此，一些长流可能会在某些路径上发生冲突，从而造成长期的拥塞，而其他路径则未得到充分利用。但ECMP不会产生平衡的负载，并会加剧拥塞热点。因此作者希望利用现有的传输来识别正在经历拥塞且需要重新路由的流，以此降低网络中的热点，并降低RPC的延迟。\n这是第一篇报告数据中心链路利用率不平衡的论文。作者定义了LI（Load Imbalance）的概念。LI是交换机上行链路的最大利用率和最小利用率的差值，代表了链路不平衡指标。作者希望拥塞链路上的一些流可以转移到具有空闲带宽的链路上。\n二、PLB设计 PLB需要两个机制：（1）检测主机处的拥塞或链路故障的机制，以及（2）端主机重新路由特定流的方法。PLB在TCP协议和Google的传输协议Pony Express上都进行了实现，均接近50行代码，拥塞检测算法和调度算法伪代码如下图。\n首先，发送方主机通过传输检测到连接正处于拥塞状态。PLB-TCP发送方使用一个简单的类似DCTCP的启发式算法来检测连接是否拥塞。发送方计算每次往返过程中带有CE拥塞标记的数据包的分数。当这个分数大于一个常数，那么这个轮是拥塞的。在经历N个连续拥塞轮后，将这个流标记为拥塞。然后PLB通过为后续传出数据包分配一个新的随机生成的流标签，来重新建立连接，当发生重传超时（RTO）时，PLB也会重新建立路径。当流重新开始传输时，没有数据包传输，因此路径更改也不会导致重新排序。\nPLB以FlowBender的早期工作为基础，提出了两个改进:①当FlowBender需要过载VLAN标记，这意味着VLAN不再可以自由使用，并且限制了可能受到影响的网络路径的长度。PLB则改为使用IPv6流标签。它允许主机在可用路径集中随机更改流的路径，而无需应用程序参与。②FlowBender只是在出现拥塞时移动连接，PLB则是等到流变为空闲后再重新指定路径，以最小化由于数据包重新排序而导致的传输交互。\nPLB的特点是对于减少小型RPC的尾部延迟是有益的。由于发送小RPC的连接经常空闲，PLB倾向于将它们从由重流或大RPC的队列的路径上移开。其次PLB和拥塞控制具有时间尺度分离的特点，这意味着PLB等待拥塞控制动作并降低发送速率，当拥塞控制不能调整时，PLB触发重路由。作者把PLB与热扩散过程联系起来。其中拥塞驱动了流的移动。拥堵越严重，流的流动就越频繁。\n三、实验部分 PLB在交换机和应用程序之间均能产生增益。先来看交换机层面数据：作者使用全局遥测监控来获取每个交换机端口的数据，计数器每30s统计一次，同时记录由于输出缓冲区溢出而转发的字节数和丢弃的数据包数。下图左侧代表ToR交换机，蓝线黄线代表PLB部署前后LI指标。在PLB启用之后，负载更加均匀地分布，第50和99百分位数LI降低了70%，明显向较低LI转变。ToR的平均LI从13%下降到4.5%，显著的利用率下降被转换为在该交换机处的分组丢弃降低约50%。\n下图右侧展示了数据中心网络中所有聚集层交换机的上行链路之间的最大利用率的前后分布。最大利用率捕获了最繁忙端口交换机可用的空间，随着交换机的最大利用率下降，分布图向左移动，并且图在尾部周围变得更加平坦，这增加了瞬态突发的空间。从而将最大利用率峰值从0.6移到0.5。这些示例表明PLB在最需要的地方（即网络热点）提供了显著帮助。转化为丢包率下降了33% 。\n作者希望评估PLB对利用率和负载不平衡的不同组合的影响，接下来作者研究整个Google车队的ToR交换机上行链路。在如此大的运行规模下，整个车队的ToR交换机涵盖了一系列具有不同负载不平衡状态的利用率水平。对于车队中的每个ToR交换机，我们从PLB部署前后两天的测量中收集以下两个指标：LI和最小端口利用率。最小端口利用率与LI反映出ToR上行链路端口的利用率范围。\n作者分别计算了部署之前和之后的数据的质量分布变化图，并对样本进行一化处理，其中横纵坐标对应于最小利用率和LI。图颜色反映了启用PLB时所经历的百分比变化。红色表示计数增加，而蓝色表示计数减少。LI接近于0的红色区域表明，在部署PLB后，更多的质量移动到该区域，蓝色阴影显示的高LI区域的质量相应减少，因此PLB更好地实现了负载均衡。\nPLB在应用程序上获得的增益体现在两个代表性工作：使用TCP的存储服务和使用Pony Express的分布式文件系统上。存储服务（TCP）：存储占Google数据中心流量的大部分。许多应用程序都使用它通过TCP上的RPC进行读写操作。托管这些存储服务器的ToR很容易由于快速的工作负载变化而成为热点。我们研究了小型和大型RPC的网络传输延迟。数据从车队遥测系统中采样，作者测量从第一个字节离开发送方到收到ACK的传输延迟。\n作者比较了一个数据中心的存储服务器在PLB部署前后7天的RPC传输延迟变化，在这段期间，整体工作量没有较大改变。下图显示了存储工作负载的小RPC对传输延迟的影响。它们的延迟由物理传播延迟限定下限。可以看到第99百分位数下降了大约20%，而第25百分位数略有上升。说明PLB将更多的流量推向利用率较低的链路，这意味着在较低的百分位数处传输延迟略有增加。\n分布式文件系统（Pony Express）：下图看到的是低延迟文件系统的截止日期超过率分布。应用对尾部延迟敏感：未能在截止日期之前完成的事务将被取消，并且促使更昂贵的恢复。PLB将该应用程序的中值错误率降低了约66%。\n四、总结 PLB是实现数据中心链路级负载平衡的一种简单而有效的方案，它通过google 数据中心网络完全部署，并产生了显著的收益。PLB是一种简单的机制，并很好地结合了交换机端口之间的异构性，传输协议和拓扑结构。论文中第5节，还有很多PLB与其他机制的更有趣的交互。一些未来的工作包括PLB的理论建模，以及与流量工程的紧密结合，以降低其最终的复杂性。\n五、思考 首先像PLB这种简单而通用的解决方案总是具有强大的价值增益，因为它结合了低成本和广泛的适用性。其次PLB将传输拥塞作为一个整体进行考虑，不仅仅是基于端到端的检测，而将中间的交换机等都包含在内，是更全面而合理的。\n","date":1672817567,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1672817567,"objectID":"9aaa7552d29dd6c56e4a0aae277c3c66","permalink":"https://ai4network.github.io/zh/post/paper-sharing-8/","publishdate":"2023-01-04T15:32:47+08:00","relpermalink":"/zh/post/paper-sharing-8/","section":"post","summary":" 今天给大家介绍的论文是由Google的研究团队提出的PLB——一种建立在传输协议和ECMP/WCMP之上，用于数据中心网络以减少网络热点的链路负载平衡设计。\n","tags":["paper sharing","SIGCOMM22","陈鑫"],"title":"SIGCOMM22 论文分享 | PLB: Congestion Signals are Simple and Effective for Network Load Balancing","type":"post"},{"authors":["宋丛溪"],"categories":["Paper Share"],"content":" “在远古时候，煤和钻石属于同一种物质，但经过上亿年的时光，它们却成为了两种不同的物品。那么，是什么造成的呢？是压力的作用。受压力小的变成了煤，而受压力大的，变成了钻石。”但是，当手机的内存压力变大时，视频的QoE反而变得更糟糕，此时，压力并没有促成更有价值的钻石的产生，而是生成了煤炭。\n今天介绍的文章是发表在CoNEXT22会议上的，作者是来自LUMS的团队。本文做了大量的实验探究视频播放设备的内存压力与视频用户体验之间的关系，并给出了几点解决方案。\n背景 随着智能手机的广泛应用，人们愈发热衷使用手机收看视频，根据资料显示，在2021年，全球有63%的智能手机用户收看Youtube。平均美国成年人，每天收看至少50分钟的视频。并且，人们愈发追求更高清的视频内容和更流畅的观看体验，这就对视频内容的分辨率和帧率有了更高的要求。\n先前研究视频传输的工作较多关注于网络对传输的瓶颈，即如何在网络带宽不足的情况下调整视频传输的码率。但是，较少人关注到，视频播放设备本身（内存、CPU等性能）也会对视频用户体验造成影响。于是，本文从内存的分析出发，探究对视频QoE的影响。\n首先，我们来介绍一些手机内存相关的背景知识：\n1.手机内存中也是采用页表管理，页可以可分为三类，一是被进程使用中的内存（Used），二是没有被使用的(Free)，三是缓存在硬盘上的页(Cached)，需要的时候可以被回收。\n2.两个可以被用来回收内存的守护进程，The kernel swap daemon (kswapd)负责回收背景中的内存，Low-memory killer daemon (lmkd) 用来在低内存状态时杀掉其他进程回收内存资源。\n针对运行中的应用，内存压力可以被分为四个等级：Normal：没有内存压力; Moderate: kswapd启动，开始回收内存; Low：回收不足，已经影响前景应用的性能; Critical：不能再维持任何的背景进程，甚至要杀掉前景进程。\n实验一、手机内存压力分析实验 在了解了上述背景之后，作者进行了大量的实验分析，从手机内存压力分析实验到内存压力与视频QoE关系的实验层层递进。首先是进行了内存压力分析实验。 在这一实验当中，采用了自己设计的signalcapter应用，在背景中收集内存压力信号进行分析，受试者80人，手机内存从1GB-8GB不等，共收集了9950小时的实验数据。\n作者统计了一小时内手机出现不同内存压力信号的频率，从图中可以看出63%的手机经历每小时大于一次的内存压力，19%大于10次Critical内存压力，6.3%大于70次内存压力。所以，内存压力现象频繁出现在手机中。\n之后，作者又统计了在经历过Critical内存压力后，转移到其他压力状态的概率，以及在Critical转移到其他状态之前的持续时间。从图中可以看出，转移到Low状态大于占67.2%,并且会持续12.8秒左右的时间，这说明内存压力很难被立即缓解。 通过以上实验作者总结，手机端经常处于高内存利用状态，终端频繁观测出长时间的内存压力，内核不能快速缓解内存压力。\n实验二、手机内存压力对视频QoE影响实验 在得出实验一的结论后，作者进而开始分析内存压力对视频QoE的影响。在接下来的实验中，实验受试者使用了1GB-3GB内存的手机如下图所示，并通过从浏览器收看视频的方法进行实验。\n作者首先分析了视频丢帧率这一指标，从图中可以看出，对于1GB内存的手机，在收看720P以上的视频会产生75%的丢帧率，对于2GB和3GB的设备，在收看1080P的视频会出现25%和9%的丢帧率。\n之后，作者还分析了手机视频播放发生崩溃的情况。1GB的设备，崩溃在大于480P的视频时就发生了，在有内存压力的情况下大于720p的视频会经常发生崩溃。对于2GB的设备，大于1080P总发生崩溃，而3GB的设备没有检测到崩溃。\n作者又对比了不同的视频类型对丢帧率的影响，对于所有类别，帧率为30fps的视频只在720P以上才发生丢帧，但是对于60fps帧率的视频，随着内存压力和分辨率的上升，丢帧变得严重。另外对比不同的视频类型，新闻类画面相对静止，所以丢帧率较低。因此视频内容和视频应用的性能指标也有一定的关系。\n作者还让受试者观看Normal内存压力状态下和Moderate压力状态下的视频，并收集他们的观感。在99个受试者中，绝大多数都能感知到视频间的差距。\n原因分析 在进行了以上的实验观察后，作者开始分析内存对视频性能产生影响的真实原因。定位到了以下的三个进程，一个是负责硬盘I/O的mmcqd，它经常使用CPU并且具有较高的调度优先级；第二个是kswapd，具有较高的CPU利用率，经常在内存较低时启动回收CPU内存;第三个是lmkd，会在内存不足时杀掉视频客户端，导致崩溃。\n于是，作者通过profile工具观察了各个进程的运行情况。进程的运行状态可分成三类：(1) Running：进程占用CPU内核运行中;(2) Runnable,CPU不可用，进程等待中; (3) Runnable (Preempted), 进程等待CPU时被其他进程抢占。经过观察，mmcqd进程在Normal内存压力下运行时间处于进程中的第50名，运行0.4秒，而当内存压力转为Moderate时就变成了第6名，运行4.6秒。Kswapd也是从第14名的2.3秒跃升到了第1名的22秒。与它相比，视频客户端只有7.9秒。因此，可以看出，这些内存管理进程大量抢占了视频进程的运行时间，进而导致卡顿和崩溃的发生。\n解决方案 在进行了上述的实验观察和原因分析后，作者对视频流自适应算法设计者、平台内容提供者、系统设计者以及手机生产者提出了以下几点建议：\n1.对视频流自适应算法设计者：传统的自适应码率调整算法通常以估算网络带宽为输入调整视频的码率，算法可以将设备内存压力信号作为输入，调整码率或帧率，从而达到更好的播放效果。如图所示，如果合理降低帧率，将降低视频的丢帧率。\n2.对平台内容提供者：增强客户端的遥测，提供大量的视频编解码和帧率方案。\n3.对操作系统设计者：合理设计内存管理进程，不要过多抢占视频应用的资源。\n4.对于收集生产者：分配给小内存的设备更多的CPU资源，可以提升视频播放的性能。\n总结与展望 另辟蹊径：转换思路，脱离从网络与视频QoE的传统角度，分析设备本身的性能和QoE的关系。\n写作思路：大部分论文的写作思路一种是从实验观察到问题发现再到提出方法解决和实验验证，另一种是通过理论建模到提出优化方案再到实验分析或理论证明。而本文是通过大量的实验一步步观察挖掘出设备本身的指标与应用性能之间的联系，并建设性地提出解决方案。从中可以看出，学术研究的重点不一定要放在解决问题上，发掘一个好问题也是十分关键的，这样一来问题可以牵引出新的研究点，启发人们从新的角度去提出更多的解决方案。\n","date":1672017257,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1672017257,"objectID":"5214cc7a521e8f51618888eda808abf2","permalink":"https://ai4network.github.io/zh/post/paper-sharing-7/","publishdate":"2022-12-26T09:14:17+08:00","relpermalink":"/zh/post/paper-sharing-7/","section":"post","summary":" “在远古时候，煤和钻石属于同一种物质，但经过上亿年的时光，它们却成为了两种不同的物品。那么，是什么造成的呢？是压力的作用。受压力小的变成了煤，而受压力大的，变成了钻石。”但是，当手机的内存压力变大时，视频的QoE反而变得更糟糕，此时，压力并没有促成更有价值的钻石的产生，而是生成了煤炭。\n今天介绍的文章是发表在CoNEXT22会议上的，作者是来自LUMS的团队。本文做了大量的实验探究视频播放设备的内存压力与视频用户体验之间的关系，并给出了几点解决方案。\n","tags":["paper sharing","SIGCOMM22","宋丛溪"],"title":"CoNEXT22 论文分享 | Coal Not Diamonds: How Memory Pressure Falters Mobile Video QoE","type":"post"},{"authors":["韩雪强"],"categories":["Paper Share"],"content":" 今天分享的是来自MIT的Venkat Arun,Mohammad Alizadeh和Hari Balakrishnan三位学者发表在SIGCOMM的一篇论文。论文讨论了基于延迟的拥塞控制算法存在着极度不公平现象，从算法的机理出发进行说明，具有较强的理论性。同时这篇论文也是SIGCOMM22的最佳论文。\n动机与背景 随着目前视频以及交互式应用的不断发展，用户对低时延的需求越来越迫切。为了保证传输层的服务质量，基于时延的拥塞控制应运而生，例如BBR、Copa以及PCC等算法。这些拥塞控制算法主要为了在防止引入排队时延的情况下，实现链路的高利用率。但是，该论文发现当共享瓶颈链路的多条流使用同一种基于时延的拥塞控制算法时，存在某些流饿死现象——一种带宽分配的极度不公平现象。\n问题引入 1. 延迟收敛现象 作者提出诸如BBR、Copa以及PCC等基于延迟的拥塞控制算法均存在一种延迟收敛现象。延迟收敛是指当算法稳定后，发送方与接收方之间的端到端延迟稳定在一个固定区间内，区间上边界记作dmax,下边界记作dmin，区间长度记作δ(C)。\n2. 非拥塞延迟 作者指出当前端到端延迟一共包含三个主要部分:传播延迟(常数)、拥塞延迟(排队延迟)以及非拥塞延迟。wifi的延迟应答、内核对数据包的处理延迟以及发送方/接收方的突发传输/应答等机制均会带来非拥塞延迟。通过上述非拥塞延迟的举例可以看出非拥塞延迟是一个随机值，和稳定后的拥塞延迟一样处在一个固定区间内波动。由于拥塞延迟和非拥塞延迟行为相似因此很难加以区分。作者将非拥塞延迟的波动区间记作D。\n3. 饿死现象 Copa拥塞控制算法族的链路的发送速率与数据包排队延迟成反比关系，如下图所示。从图中可以看到当算法稳定时对排队时延的不同观测所导致的链路发送速率有着巨大差异。同时由于端对端延迟中非拥塞延迟的干扰，对排队时延的观测往往是不准确的，这种观测上的差异也就导致了数据流之间的发送速率出现较大差异，甚至发生饿死现象。\n下图中有两条流共享同一个瓶颈链路，一条流记作流1使用CCA1拥塞控制算法同时该条数据链路使用的wifi接收方引入了一定的非拥塞控制延时，另一条流记作流2使用CCA2拥塞控制算法。流1因为存在非拥塞延迟的干扰过高估计了当前的排队时延，就导致流1会降低发送速率，造成不公平现象。\n问题证明 1.两个定义 f-高效的CCA 如果在具有瓶颈链路速率C和最小RTT RM的理想路径，拥塞控制算法(CCA)最终获得至少f C的吞吐量。\nCCA的s-公平性 从任意初始条件开始的两个流 f1 和 f2（例如，其中一个流可能运行了很长时间，而另一个流刚刚开始）。如果始终存在一个有限的时间 t，使得对于超过 t 的所有时间，较快的流与较慢的流实现的吞吐量之比小于 s，则网络是 s 公平的。\n2.三步证明 作者通过Copa算法族引入了饿死现象，且认为所有基于时延的拥塞控制算法均存在这个现象，并通过以下三步进行证明。\n1）假定数据流的延迟上限为dmax，下限为Rm。我们在[Rm,dmax]之间可以构造有限个长度为δmax,且彼此之间的距离为ε的排队延时族。同时定义这些波动的排队延时对应的带宽分别为λ0=λ，λ1…,且。根据鸽笼原理易得一定存在两个排队时延区间位于δmax+ε内。\n2）根据第一步的说明，可以构造两条独立的数据流，其分别具有带宽C1和C2(如图4)。可以构造两个CCA，其收敛后的排队时延记作d1(t)，d2(t)差距小于ε且分别获取x1和x2的速率(如图5)。可以说明x2比x1的s倍还大。\n3）当两条流共享同一瓶颈链路时，假定将η1(t),η2(t)∈[0,D]记作两条链路的非拥塞延迟，d1(t),d2(t)记作两条链路的拥塞延迟。为了构造第二步的时延要求，我们需要控制η1(t),η2(t)使得η1(t)+d1(t)=d1(t)以及η2(t)+d2(t)=d2(t)。根据证明(具体见论文附件A)，我们可以得到d*i(t)的表达式如下：\n易得，d*i(t)具有以下两种性质:\nd*i(t)\u0026lt;min{d*1(t),d*2(t)}\nmax{d*1(t),d*2(t)}\u0026lt;d*i(t)+D\n根据以上两种性质我们知道可以获得 η*1(t),η*2(t)∈[0,D]，使得当两条流共享瓶颈链路时存在 η*1(t)+d*1(t)=d1(t) 以及 η*2(t)+d*2(t)=d2(t) 的可能性。一旦发生这种现象，就出现饿死。\n实验验证 针对上述理论证明作者给出了两个在模拟环境下的进行的实验进行说明理论证明的结果是正确的。\n1. BBR 作者使用Mahimahi仿真平台上构造了两个共享同一瓶颈链路的BBR数据流，其传播时延分别是40ms和80ms，共享瓶颈链路的带宽是120Mbit/s。实验进行了60s的持续传输，最终出现一个流获得8.3Mbit/s，另一个获得107Mbit/s。\n2. Copa 作者使用Mahimahi仿真平台上构造了两个共享同一瓶颈链路的Copa数据流，其传播时延均为60ms，共享瓶颈带宽为120Mbit/s。作者引入一个干扰使得其中一条流的时延估计为59ms，导致了其低估了传播时延也就意味着其之后均会高估排队时延，最终导致两条流的带宽分配为:8.8Mbit/s、95Mbit/s。\n可行的解决方案 1. 故意的延迟震荡 根据上面的分析我们得到基于延时的拥塞控制算法产生饿死的根本原因在于其追求低延时即延迟收敛。但是基于丢包的拥塞控制算法采用AIMD的方式填充队列，并不会产生饿死现象。因此作者认为可以允许基于时延的拥塞控制算法像AIMD式的拥塞控制一样容忍更大的延迟波动来对抗非拥塞时延的干扰。\n2. 显式拥塞信号，包括ECN等。 心得体会 本文以理论分析切入，从基于延时的拥塞控制算法的机理开始，发现这些算法最终导致自己违背了自己的初衷——公平性。文章的最后作者给出了几种针对饿死现象的解决方案，可以作为以后基于延时的拥塞控制的切入点。近年来，BBR以及Copa的大火，使得很多人认为基于丢包的算法已不具有竞争力。但从本论文的视角来看，基于延时的拥塞控制算法比如Copa，BBR等也存在着很大的不足，并不会导致基于丢包的拥塞控制算法退出历史舞台。\n","date":1671519067,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1671519067,"objectID":"777d57c3b203cbebb23006c31f18ce82","permalink":"https://ai4network.github.io/zh/post/paper-sharing-6/","publishdate":"2022-12-20T14:51:07+08:00","relpermalink":"/zh/post/paper-sharing-6/","section":"post","summary":" 今天分享的是来自MIT的Venkat Arun,Mohammad Alizadeh和Hari Balakrishnan三位学者发表在SIGCOMM的一篇论文。论文讨论了基于延迟的拥塞控制算法存在着极度不公平现象，从算法的机理出发进行说明，具有较强的理论性。同时这篇论文也是SIGCOMM22的最佳论文。\n","tags":["paper sharing","SIGCOMM22","韩雪强"],"title":"SIGCOMM22 论文分享 | Starvation in End-to-End Congestion Control","type":"post"},{"authors":["韩雪强"],"categories":["Paper Share"],"content":" 今天分享是由两位来自Pittsburgh大学的两位学者发表在mobicom22上的一篇论文。该论文主要聚焦于解决当前在性能较弱的小型嵌入式设备上部署神经网络模型并进行实时推理的困难。文章提出了Agile NN——使用可解释神经网络与需要部署的神经网络模型进行协同离线训练，实现将原本需要在线推理的计算迁移到离线训练过程中，进而达到在小型嵌入式设备上部署并实现更加精确的实时神经网络推理。\n研究动机 随着人脸识别、语音识别等深度学习模型与工业物联网的不断发展，在小型嵌入式设备上部署深度学习模型的需求迫切。但是小型嵌入式设备的内存以及计算能力较弱而深度学习模型的部署与实时推理需要大内存和强算力，因此如何在小型嵌入式设备上部署深度学习模型并进行实时推理成为一大难点。在以往的研究中，研究人员提出了三种解决方案。\n1.本地推理(fig.1-topleft)\n该方案通过对神经网络的权重和结构进行压缩和裁剪操作，减小部署以及运行模型的代价。但是该方案只能在诸如智能手机等具有较强性能的嵌入式设备上进行运行，一旦迁移到小型嵌入式设备上，由于神经网络压缩程度过高导致实时推理精确度下降。\n2.远程推理(fig.1-topright)\n该方案通过云端协同的方式，将嵌入式设备使用深度学习模型的负担迁移到云平台上，利用云服务器的强大性能减少了本地性能压力。但是为了实现云端协同的实时性，需要对神经网络的输入数据进行压缩，损失部分特征(甚至是及其重要的特征)。同时小型嵌入式设备为了节约电量的目的，仅仅使用低速的无线射频信号进行数据传输，导致本地数据需要较大时延传到云端，影响模型的实时性需求。\n3.神经网络切分(fig.1-buttomright)\n该方案在本地部署神经网络用于特征提取以及压缩，同时在云端部署推理神经网络模型。但是部署在本地的神经网络模型为了增强特征稀疏性引入了巨大的计算压力。\n为了解决在嵌入式设备上部署实时推理模型的问题，该论文采用神经网络切分的结构，但是论文分析了以前采用神经网络切分中特征数据压缩的比例对云端实时推理的精确性和通信延迟的影响，得出结论:在神经网络切分的结构中通信延迟与实时推理的精确性具有互斥性。为了解决这个问题，本论文采用可解释神经网络方法例如梯度积分(IG)，分析特征数据中对实时推理精确度较为重要的特征(记作top-k特征)保留在本地进行推断，而其余特征数据进行压缩传输到云端输入到神经网络推断模型中进行推理，将两个推理结果进行综合得到最终结果。整个系统离线训练与在线推理结构如fig.5所示，其中嵌入式设备上运行已经训练完成的可解释神经网络和本地经过压缩的实时推理模型，远程云端运行未经压缩的实时推理模型。\n下面主要进行AgileNN离线训练部分介绍。AgileNN离线训练包含两个部分:可解释神经网络训练(论文中又称为特征提取器)和实时推理模型训练。但是可解释模型特征重要性评估的精确度依赖于实时推理模型的精确度，因此本论文在训练可解释神经网络模型时，选择了先预训练实时推理模型，在将可解释神经网络模型和实时推理模型进行协同训练。\n1、可解释AI(因为可解释AI技术并不是该论文的主要创新点且论文的可解释AI算法是可被替换的，因此在此处不对可解释AI技术展开介绍，只对论文中如何使用可解释AI技术进行讲解)\n本文默认使用的可解释AI的技术为积分梯度法(IG)，该方法旨在解释模型特征与预测结果之间的关系。由于IG广泛适用于任何可微分模型、易于实现且具有较高的计算效率因此被普遍使用。fig.3为IG方法分析图像分类器中输入图像像素特征重要性的流程。\n1）特征重要性倾斜度(Skewness of feature Importance)保证\n特征重要性倾斜度是指由特征提取器分析出的各个输入特征之间重要性差距大小，不同特征之间重要性差距越大代表特征重要性倾斜度越大(fig.4为实例)。在该模型中为了保证本地模型推理的精确性以及更大程度的压缩不重要特征属性保证低通信延迟，作者希望可解释AI工具输出的特征重要性分布差距越大越好。为了达到这个目的，在进行特征提取器训练时将重要性分布作为损失函数的一部分，记为，Lskewness。其中ρ代表top-k特征的重要性阈值。\n$$ L_{skewness} = \\max(0,\\rho - |\\overrightarrow{I_1}|) $$ 2）特征排序\n因为特征提取器在嵌入式设备中运行时，要确保top-k特征一定要对应设备的前k个输出管道(由于嵌入式设备硬件逻辑限制)，因此在进行特征提取器离线训练时要确保特征按照重要性进行“非严格降序排列”(保证top-k的特征一定排在其他特征的前面)。作者将排序也作为特征提取器的损失函数的一部分。其中，I代表未排序的特征重要性向量，Isorted代表降序排序的特征重要性向量。\n$$ L_{descent} = ||\\overrightarrow{I} - \\overrightarrow{I}_{sorted}||_2^2 $$ 2、实时推理模型\nAgileNN的推理模型包括本地模型和远端模型两部分(fig1-buttomleft)，分别用来处理top-k特征和其余不重要特征的推断。针对远端推断结果和本地推断结果进行加权相加。\n$$ Result = LocalNN-R *α+RemoteNN-R*(1-α) $$ 关于α的确定，作者选择了sigmoid函数。其中，w和T均为超参数。\n$$ \\alpha(w;T) = \\frac{1}{1+e^{-w/T}} $$ 实验验证 作者将模型部署在STM32F746上，并在四个数据集CIFAR10/100、SVHN、ImageNet-200上进行测试。实验模型部署细节如fig.14。\n作者在数据集上与现有的4个算法进行了对比。根据fig.16，实验结果显示NgileNN有效减少了云端通信的延迟并且增加了实时推断的精确度。\n针对模型需要花费的部署以及运行开销，作者也进行了评估。根据fig.19可以看出AgileNN运行开销(以消耗的电量为基准)远低于其他模型。根据fig.20可以看到AgileNN在极少的内存占用的情况下实现了较高的推断准确性。\n个人总结 该论文通过使用可解释AI技术有效地将深度学习实时推理模型的在线算力负载迁移到离线训练中，实现了在性能较弱的嵌入式设备中部署并运行深度学习模型同时保证了推理的精确度。论文向我们展示了可解释AI技术的应用，详细介绍了可解释AI的训练以及模型协同训练，可以作为可解释AI工程落地的参考。\n","date":1671448583,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1671448583,"objectID":"c80df19afdd9060adcc5773cf2b5c2ba","permalink":"https://ai4network.github.io/zh/post/paper-sharing-5/","publishdate":"2022-12-19T19:16:23+08:00","relpermalink":"/zh/post/paper-sharing-5/","section":"post","summary":" 今天分享是由两位来自Pittsburgh大学的两位学者发表在mobicom22上的一篇论文。该论文主要聚焦于解决当前在性能较弱的小型嵌入式设备上部署神经网络模型并进行实时推理的困难。文章提出了Agile NN——使用可解释神经网络与需要部署的神经网络模型进行协同离线训练，实现将原本需要在线推理的计算迁移到离线训练过程中，进而达到在小型嵌入式设备上部署并实现更加精确的实时神经网络推理。\n","tags":["paper sharing","MobiCom22","韩雪强"],"title":"MobiCom22 论文分享 | Real-time Neural Network Inference on Extremely WeakDevices: Agile Offloading with Explainable Al","type":"post"},{"authors":["李亚辉","计晓岚"],"categories":null,"content":"点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/B1P5KTsmzDA7\n腾讯会议：961-601-710 会议密码：123456\n","date":1670009400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1670009400,"objectID":"8e6190c477ebd2232355ac94ae66bac6","permalink":"https://ai4network.github.io/zh/event/7/","publishdate":"2022-12-02T19:30:00Z","relpermalink":"/zh/event/7/","section":"event","summary":"点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/B1P5KTsmzDA7\n腾讯会议：961-601-710 会议密码：123456","tags":[],"title":"2022年秋季学期第16周组会","type":"event"},{"authors":["徐草"],"categories":["Paper Share"],"content":" 本期分享SIGCOMM22拥塞控制专题下的论文： Achieving Consistent Low Latency for Wireless Real-Time Communications with the Shortest Control Loop。该文作者来自清华大学、阿里巴巴与卡耐基梅隆大学。\nSIGCOMM22 | 诸葛: 跳过last-mile的拥塞控制回路 实时会议与云游戏这类RTC应用需要持续稳定的低延迟来提供良好的交互体验。然而无线网络只能提供较好的延迟中值，当带宽波动时其尾部延迟可能很大。文章发现当无线AP处发生拥塞时，RTC的控制回路会膨胀，导致发送方无法自适应地及时调整发送速率。因此以缩小控制回路的思路设计了“诸葛”：使数据包在到达无线AP时就预测其延迟，并立即将预测值传回发送方，避免拥塞控制信号经历last-mile的拥塞过程，从而达到加快发送方反应速度的效果。实验结果表明诸葛能将尾部高延迟的比例以及RTC性能降级的情况减少17%到95%。\n1.简介 RTC（Real-time Communication）应用需要持续低延时，这在无线场景中并不能被满足，问题主要出现在尾部：\n无线用户的RTT中位数低于100ms，与以太网用户相当；但99分位数的尾部延迟约400ms，意味着播放20帧的视频时每5s就会出现一次高延时。观察还发现无线用户经历的重缓冲是以太网用户的两倍。\n对于无线场景（论文关注last-mile）来说，可用带宽的骤变（可能由多用户接入或人为干扰引起）会导致暂时拥塞，让数据包在无线AP内排队，导致端到端延迟变大。对此，理想情况是发送方立刻减小发送速率以防止排队、高延迟、丢包的出现。但实际情况是发送方的反应速度恰恰被排队给限制了。\n如何解释？拿TCP中时延敏感的拥塞控制算法来说，其拥塞信号是RTT变大。虽然数据包到达AP时就遭遇拥塞 ，但发送方仍需等待一段时间才能得知拥塞。这段时间包括：该数据包从AP中出队，AP转发给接收方，接收方再发送ACK经AP返回至发送方，发送方收到ACK计算RTT得知拥塞。这个过程中拥塞信号经过的路径与数据包及其ACK经过的一致。图1中五步表示拥塞信号的传递路径（控制回路），红色的是在发生拥塞时膨胀（时间变长）的部分，表明拥塞越严重，发送方就需要越久才获取拥塞信号。\n因此论文的关注点在：让拥塞控制回路从完整的数据包传输路径中解耦，从而防止其经历排队与无线网络的延迟。如上图所示：在数据包进入（i）之前，发现出现拥塞时，预测其后续可能经历的延迟，随即让AP将预测值通过（iv）把拥塞信号传给发送方，从而跳过膨胀的（i）（ii）（iii），也就是绕过拥塞瓶颈。\n要实现文章的想法（减少控制循环），主要会有两个问题：\n数据包还没真正经历延迟，如何预测？ AP怎么把拥塞信号（预测的延迟）传给发送方？ 对此论文提出了诸葛，目的是最小化拥塞控制回路，从而达到无线网络环境中的持续低时延。诸葛包括两个模块：“算命先生”（Fortune Teller，后文简称FT）和“反馈更新器”（Feedback Updater，后文简称FU），前者基于两部分预测时延，后者根据不同协议特点，更新并上传预测的延迟。\n2.背景和动机 2.1 理解无线网络的尾部延迟 为什么尾部延迟对于无线网络中的RTC应用那么重要？ 为什么无线网络的尾部延迟更明显？ 对于第一个问题，一言以蔽之：RTC应用需要的低延迟不只是中值（median）小，尾部（tail）值也要低，但目前的无线接入网的情况无法满足后者。文章给出了统计：\n文章认为不管是4G、5G还是WiFi的尾部延迟都不够好。假设在大部分时候无线网络用户拥有良好的RTT(\u0026lt;100ms)，但其99分位数的RTT\u0026gt;400ms，这就会导致每百帧就有一帧高延迟。\n文章还测试了他们自己的RTC应用（日活跃量百万用户），对比了以太网、WiFi、4G接入网络的网络状况和应用表现，如下图2。\n并观察得出：\nWiFi和4G的表现相近; 400ms RTT时前两者为1%，以太网则在千分位与万分位之间；\n应用层的帧延迟\u0026gt;400ms的前两者的比例是以太网的2倍； 应用层帧率\u0026lt;8时前两者是以太网的10倍。 对于第二个问题，明显的尾部延迟源于：发送速率与瓶颈队列可用带宽 (Available Bandwitdh, ABW) 的不匹配。从AP的视角来看，如下图：\n蓝线表示RTC流的ABW在瓶颈处（连接client的AP）骤降k倍，此后CCA需要一个控制回路 𝜏 才降低发送速率（绿虚线）。而在此 𝜏 期间，瓶颈队列仍以发送方的原发送速率接收数据包，这些过多的包会开始排队（红色块），需要 k𝜏才能被排空 。排空期间所有的包都会经历更高的延迟。所以影响延迟的骤变程度的因素为：（i）ABW波动程度→k（ii）发送方反应速度→𝜏。\n无线信道的多变性导致了其比有线信道波动更大 。文章根据开放数据集、实测数据，以200ms为周期（认为这是CCA反应时间）计算带宽。结果如下图，横轴代表下降的倍数，纵轴代表小于相应倍数的占比，实线是开放数据集，虚线是文章所测，可以看到以太网的下降更少：\n无线网络的波动程度让其尾部延迟更明显，要想缓解就需要让发送方反应速度更快。\n2.2 现有解决方案 有很多创新工作提升了连接中的稳定状态下的中值（steady state median）延迟。比如BBR（CCA）通过维持空队列来保证延时；CoDel（AQM）会丢队列前端的包加快拥塞反馈；还有根据不同反馈信号来维持良好工作状态。不过文章认为这些工作还不足以减少尾部延迟，并进行了分析：\n******************************************基于端用户的解决方案。******************************************主要问题还是前面说的拥塞控制的控制回路中的无线部分会在拥塞发生时膨胀，延迟拥塞信号的反馈。\n下图4a展示模拟实验中，带宽降低不同倍数时，时延敏感CCAs（BBR、Copa和GCC）与AQMs的表现。\n当ABW降低十倍以上时，所有这些算法，无论是否使用延迟感知AQM，都会有数秒的RTT降级时间。\n**********************基于网络内部的解决方案。**********************CoDel通过丢弃队列前部的包试图加快拥塞信号的生成，但信号仍会经历（ii）和（iii）的无线延迟（可能超过100ms）。此外，AQM主要设计用于丢弃一些数据包，而许多CCAs对丢包并不敏感。图4a可以验证：CoDel几乎无法改善如Copa这种基于时延的CCA。也有一些方案是协调端和网络路由器来达到更好的网络反馈，比如XCP、RCP、Kickass和ABC。但文章认为它们的目标是从路由器获取更好的网络状态估计，收集到的信息却还是要经历完整的控制回路。\n2.3 论文方案：减小控制回路 论文的想法很直接，就是通过尽快感知拥塞，并及早反馈来缩小控制回路。另外还想方便部署。\n**最早的信号。**相对于丢包率、实际延迟这些拥塞信号来说，是否会有更早的信号？文章认为有：大部分情况下，数据包到达瓶颈队列时就可以预测自己的延迟。比如包的排队延迟可以通过队列大小除以出队速率来大致估算。因此预测的排队延迟是ABW下降的最早信号。论文作者受此启发，想利用这个最早信号来加快发送方的反应速度。\n****************************************快速反馈最早信号给发送方。****************************************发现了最早信号没用，还要赶紧发给发送方。理想方案是直接告诉发送方当前的队列状态，让信号绕过控制回路中膨胀的部分。\n**只改last-mile路由器方便部署。**回顾传输层设计历史，有很多优秀的工作未被实际应用。像XCP、RCP、Kickass、ABC和active network等都需要同时更改服务器端和路由器。但是服务器通常由谷歌、Facebook这些内容提供商控制，而路由器则由Netgear、华为、思科这些厂商提供，协调他们一起推进一项传输创新工作比较麻烦。所以论文提出：只改“最后一英里”的路由器，方便其大规模部署。\n3.诸葛的设计 本文把自己的工作取名Zhuge，希望像诸葛亮一样神机妙算、未卜先知。\n3.1 设计的挑战 诸葛的设计主要两点，网络状态的准确估计和快速反馈：\n第一点的难点在于流量的突发性：一是RTC流的数据包的突发式到达。RTC应用以视频帧为单位生成内容，为了减少端到端延迟，发送方倾向于突发性地发送同一帧的数据包。导致即使在稳定状态下，也可能快速出现排队现象。**二是无线信道上的数据包的突发式离开。**无线网络的共享性导致了无线信道资源的竞争和频繁的带宽波动。无线协议倾向于聚合多个数据包同时出队。\n简单的估计方法是将队列长度除以出队速率。然而，这种方法面临着瞬态-稳态矛盾（transience-equilibrium nexus. 参考文献见文末）：比如在计算出队速率时时间窗口长度的设定，窗口短则易波动，导致稳态期间也可能有明显波动，而窗口长则无法捕捉瞬态的延迟波动。许多拥塞算法都存在无法兼顾瞬态与稳态性能的问题。\n第二点。如何将估计的无线网络状态尽快告知发送方？直接的方法是可以构建一种新的反馈包给发送方，但对于现实中部署的大多CCAs来说，网络状态不是显式传递的（有可能根据ACK进行计算），直接把网络状态告诉发送方，后者不能直接理解，而需要同时修改发送方，这与论文之前提的“只改AP，方便部署”的理念背道而驰。\n另外，实际采用的传输层协议和CCAs高度多样化：不同传输协议头可以是不加密（TCP）或加密（QUIC）的；RTC应用也可能会定制化CCAs，使用不同信号来调整发送速率，有的还会在内核中修改TCP CCA。基于RTC的应用会将网络状况定期汇总到一个特殊的反馈包中显示反馈。面对不同的CCAs，该如何把网络状态有效传递给发送方呢？\n3.2 框架概览 诸葛针对上述两个问题各自设计了一个模块：算命先生 Fortune Teller, FT 和反馈更新器 Feedback Updater, FU。\nFT为了克服瞬态-稳态矛盾，将排队延迟分割成长期和短期延迟。\nFU将RTC应用中的现有协议分为带外（out-of-band）反馈和（in-band）带内反馈两类。对于带外反馈协议，反馈包的到达就是给发送方的信号（比如TCP中的ACK包）。带内反馈协议在反馈包的有效载荷中携带网络状态，比如WebRTC中的transport-wide congestion control Feedback（TWCC-FB）包。FU用不同逻辑更新修改两类反馈。\n下图5是诸葛的完整工作流程：\n当一个包通过以太网端口到达无线接入点时，FT会预测其延迟，同时照常转发给下行队列。FU则把预测信息更新到去往发送者方向的反馈包里。这个过程中，会将最早的信号绕过控制回路的排队延迟和无线传输延迟，直接从AP发给发送方。\n4.“算命先生” Fortune Teller “算命”就是预测一个包何时会到达客户端，也就是它随后会经历的延迟。无线网络中的这个延迟可分为两段：在AP队列中的排队延迟和在链路中的传输延迟。\n4.1 排队延迟的预测 如3.1讨论，简单地用队列长除以出队速率预测延迟会有瞬态-稳态矛盾。文章因此将排队延迟分为两部分：长期排队延迟（qLong）和短期排队延迟（qShort），如下图6：\nqLong是一个包从刚到达队列直至来到队列前端的时间。它能覆盖由无线竞争和突发RTC流量引起的延迟波动。可以用当前队列大小除以平均出队速率来估计qLong。\nqShort是一个位于队列前端的包等待完全出队的时间，其与链路层的发送模式更相关（比如MAC数据单元的聚合会导致其波动）。\n排队延迟就是把两者相加。以图7说明，这样分开估算的好处是：\nqShort能快速检测ABW的下降。当ABW下降时，队列需要时间建立，txRate（出队速率）需要时间窗口更 …","date":1669553896,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1669553896,"objectID":"f412b564c7c6167809c520a4516d93de","permalink":"https://ai4network.github.io/zh/post/paper-sharing-4/","publishdate":"2022-11-27T20:58:16+08:00","relpermalink":"/zh/post/paper-sharing-4/","section":"post","summary":" 本期分享SIGCOMM22拥塞控制专题下的论文： Achieving Consistent Low Latency for Wireless Real-Time Communications with the Shortest Control Loop。该文作者来自清华大学、阿里巴巴与卡耐基梅隆大学。\n","tags":["paper sharing","SIGCOMM22","徐草"],"title":"SIGCOMM22 论文分享 | Achieving Consistent Low Latency for Wireless Real-Time Communications with the Shortest Control Loop","type":"post"},{"authors":["李亚辉"],"categories":["Paper Share"],"content":" 本期分享SIGCOMM22主机网络和视频传输专题下的论文：LiveNet: a low-latency video transport network for large-scale live streaming。该文作者来自中国科学院大学和阿里巴巴集团。\n1. 动机和背景 随着全球新冠疫情的肆虐，实时视频传输在我们日常生活中已必不可少。与此同时，在线视频购物、在线视频会议在这两年的受众不断增多，具有较低端到端延迟的直播方案因此备受重视。本文基于此需求，力求减少直播中的端到端延迟，即减少从直播者采集到一个视频帧到该视频帧在观众客户端上被渲染所经历的时间。\n对于在线购物而言，作者认为理想的端到端延迟应该小于1秒。如图一所示，端到端延迟又包括了四部分：第一公里延迟、CDN延迟、最后一公里延迟、缓存延迟。其对应的说明如下：\n第一公里延迟：直播者采集一个视频帧并将其编解码的延迟、推到CDN网络的接入点（称为CDN生产者）的传输延迟，这一部分通常为150ms。 最后一公里延迟：观看者从CDN网络的接入点（称为CDN消费者）拉取一个视频帧的传输延迟，加上解码渲染到屏幕的延迟。这一部分通常为150ms。 缓存延迟：为了避免网络环境抖动造成观众观看视频时的卡顿，通常在观众的客户端内缓存一定的视频帧，该视频帧的播放时长为300ms。 CDN延迟：该延迟是指CDN网络从CDN生产者接收到视频帧之后，经过转解码和CDN网络内部的传输处理之后转发到CDN消费者所经历的延迟。在端到端延迟为1s的约束下，减去上面三部分的总和，该部分延迟一般要求小于300ms。 作者在阿里巴巴工作时，观察到目前阿里的CDN网络架构无法满足300ms的CDN延迟要求。如图二所示，蓝色线条为阿里巴巴的CDN架构的平均传输延迟。一周的观测结果表明：该部分延迟通常400ms左右，超过了直播对CDN延迟的300ms的最低要求。因此，本文的目标是改进阿里的CDN的架构，以降低直播时的端到端延迟。\n2 问题引入 作者为了降低直播时的端到端延迟，尝试在两方面优化以期达到理想效果。这两方面分别是：CDN架构和CDN节点的报文转发和处理逻辑。\n2.1 传统CDN架构的问题 作者认为，阿里的基于分层的CDN架构（称为HIER）并不适合于传输对实时性有严格要求的视频流。如图三所示，HIER包含了一个统一的视频流处理中心，该部分负责处理所有视频流（比如视频编解码）以及管理其他CDN节点。CDN节点，在逻辑上分为了两层，它们负责转发视频流内容，但不处理视频流内容。因此，当一个节点收到直播者推送的视频流数据之后，需要先从L1层转发到L2层，直到根部的视频流处理中心。最后再以反方向的逻辑转发给视频流的观看者。这样一来一回将会经过五个节点。\n因此HIER存在的问题如下：\n经过的CDN节点太多，报文每转发一次都要消耗一定的时间，在时间上造成了大的开销。 上层节点是逐渐减少的，当底层的多个结点同时需要传输视频流，并且它们逻辑上和同一个高层节点相连接时，这会造成高层节点的过载，最终导致服务质量下降。 这样树形的CDN网络很难被扩展，灵活性比较低。 因此, 作者希望改进这种树形的CDN架构，将其扁平化。例如能否通过某种方式，将一个CDN生产者接收到的数据直接经过一个或者两个中转节点转发到CDN消费者节点，中间经过的路径尽可能的被减短。\n2.2 报文转发处理逻辑的问题 数据中心网络的节点与节点之间使用专网，这样的网络具有带宽高、丢包率低的特点。因此使用传统的TCP传输协议，报文不可避免的需要经过内核态的拥塞控制、流量控制等复杂逻辑，这也会带来一定的开销，对于实时性的数据传输并不友好。如图四所示，作者在阿里巴巴工作时，观察到网络丢包率最高也只有百分之0.175。基于此事实，作者认为CDN节点应该避免将报文经TCP协议栈传输，而应该直接转发，同时也应该设计一种补偿机制，在报文丢失的情况下再对其进行重传。\n3 关键技术 针对上面两个问题，下文就作者的解决方案进行介绍。\n3.1 扁平化的CDN架构 如图五所示，作者将所有的CDN节点分为了四种，分别为：\nCDN生产者节点：在直播者发起直播请求之后，通过DNS重定向到CDN生产者节点。用以从直播者接受视频帧，必要时对视频帧进行转码。 CDN消费者节点：接收观众的观看请求， 如果该请求是一个该CDN节点不知道的视频流ID，该CDN节点首先向中心节点（即图中的Streaming Brain）查询通往CDN生产者的路径，然后建立路径之后传输视频流。 如果该请求是一个该CDN节点已知的视频流ID，则直接转发属于该视频流的视频帧到观众。 中继节点：中继节点负责接收来着CDN生产者的视频帧，并缓存到本地。另外有了中继节点可以建立自CDN生产者到CDN消费者节点的多条路径。 控制平面节点：即图中的Streaming Brain，是一个整体的控制平面逻辑，又包括三个组件： 全局发现组件：收集所有CDN节点的状态信息，包括与之关联链路的负载、CDN节点本身的负载。 路径决定组件：负责接收来自客户端的路径查询请求，并返回路径。另外，当CDN生产者节点收到一个直播流，要向该组件注册，注册的数据为：\u0026lt;生产者节点ID，视频流ID\u0026gt;。 全局路由组件：根据收到的CDN节点的状态信息，计算每对节点之间的路径。更新路径到路径决定组件的路径表中。 3.2 扁平化的CDN节点工作流 以下就上图介绍该扁平化的CDN节点的工作流和其实现方法：\n3.2.1 路由表建立流程 每一个CDN节点定期更新该节点的负载信息到全局发现组件（一分钟一次）。另外，当任何一个节点负载达到一个阈值时，会立刻通知到全局发现组件。 全局路由组件收到来自全局发现组件的负载信息之后，形成一个类似网状的图，相连接的节点之间都有权重值，权重值的计算主要综合考虑一个CDN节点的负载情况、一个链路的丢包率、传输往返延迟、链路的负载情况，具体计算过程可参考论文，篇幅所限此处不再展开。然后通过KSP（最短路径算法）算法计算每一对节点之间的最短路径，随后将其更新到路径决定组件的路径表中，即PIB。另外该KSP算法会保证该路径中间的跳数少于两个节点，以避免报文转发时经过太长的路径导致CDN延迟增高。 路径表一旦收到一个过载信号，与该过载链路或过载节点相关的路径将会被作废。 3.2.2 直播流工作流程 当生产者CDN节点收到一个直播流的请求，首先会向路径决定组件注册该流，如路径决定组件中的 SIB表所示，注册的信息为\u0026lt;视频流ID，CDN生产者节点ID\u0026gt;二元组。然后接收来自客户端的视频帧，并根据本地的转发表转发该视频流。\n客户端向CDN生产者节点发起一个视频流的请求并附上相应的视频流ID。\nCDN消费者节点接收到该视频流请求之后，如果该请求是一个该CDN节点未知的视频流ID，该CDN节点首先向中心节点（即图六的路径决策组件）查询通往CDN生产者的路径，在建立路径之后才能够传输该视频流。\n假设该CDN消费者节点第一次收到对该视频流ID的请求，向路径决定模块发起查询，提交视频流ID号和其节点号DstNdID。\n路径决策组件收到该视频流ID号和DstNdID后，用视频流ID号在SIB表中查询对应的SrcNDID。接着，使用SrcNDID和DstNDID从PIB表中查询相应的三个候选路径\u0026lt;path1，path2，path3\u0026gt;，最后交付给CDN消费者节点。\nCDN消费者节点收到三个候选路径\u0026lt;path1，path2，path3\u0026gt;后, 根据自己的偏好策略从中选择一条路径。假如选择的路径为path1，其包含的节点为\u0026lt;生产者节点，中转节点1，中转节点2，消费者节点\u0026gt;。消费者节点向中转节点2发送视频流ID和path1路径\u0026lt;生产者节点，中转节点1，中转节点2，消费者节点\u0026gt;。\n中转节点2将在本地注册转发表，表项为\u0026lt;StreamID, 消费者节点\u0026gt;，译为将与StreamID相关的视频流帧转发到下一跳节点，即消费者节点。\n中转节点2重复CDN消费者节点的动作，向它的前一个节点（即中转节点1）转发StreamID和path1。直到达到根部的生产者节点。\npath1上的所有节点的转发表项建立完成之后，每一个节点收到与StreamID相关的视频帧之后，将会根据转发表项，转发到下一个节点。\n3.3 优化报文转发和处理逻辑 传统的数据中心网络使用TCP传输数据，内核态的处理逻辑太复杂，导致报文转发的迟滞。因此作者改用RTP协议结合RTCP来做，并提出了快慢路的概念。其中RTP协议用来转发数据，一旦一个节点收到一个报文，立刻将其转发到下一个节点，个人理解这是借助了RTP协议的优势：\n基于UDP可以直接转发，不需要经过TCP相应的复杂逻辑。 尽管RTP协议并不是可靠的，但提供了有序的保障，会为每一个报文标序号，并在接收方重组（因为不可靠可能出现空缺）。 RTCP协议又提供了相应的控制逻辑，接收方会将最近的丢包情况以50ms的粒度反馈给发送方，发送方据此调整其发送速率，同时将丢失的报文重发到接收方。\n整体的逻辑如图七所示，此处就该图对快慢路的主要逻辑做介绍：\n绿色部分：慢路\n接收控制逻辑：CDN节点的快路收到一个报文之后，在将其通过快路再次立即转发出去的。同时，本地留一备份到慢路上，以在丢失的时候重传。 发送控制逻辑：该逻辑会接收下游节点在快路上的丢包信息，并调整速率并反馈到快路上，同时将丢失的报文（这就是上面备份的意义）通过快路快速转发出去，重传的报文优先放在快路的转发队列前。 黄色部分：快路\n每收到一个报文，将其放入本地的发送队列中。\n报文发送器（pacer）负责将报文按照速率的要求，以相应的频率从队列中取报文并发出。\n需要注意快慢路本质上是一种逻辑上的概念，作者将其抽象，控制逻辑为慢路，其负责可靠性。转发逻辑为快路，其负责快速的转发报文，并绕开TCP协议栈。\n4 实验结果 作者在实验结果部分将所提出的工作（即LiveNet）和先前的HIER做了对比，主要关注了以下指标：\nCDN内部延迟：一个视频帧到CDN生产者，传输到CDN消费者所经历的延迟。 端到端延迟：直播者到观看者之间整体的视频流延迟。 卡顿率：用户在观看视频时，使用LiveNet和HIER在观看期间经历卡顿的概率。 快速启动率：从观看者点击一个直播视频开始计时，到接收到第一个视频帧的时间是否低于一秒，低于一秒，为快速启动。 接下来对作者的实验结果做一些介绍：\n首先看图二，为期一周的测量结果表明，LiveNet（蓝色部分）相比HIER（红色部分）大幅度降低了CDN内部延迟，从平均的400ms延迟降低到了200ms左右。另外根据图八的CDF图所示，百分之五十以上的视频流在经过LiveNet传输时，端到端延迟都能满足在一秒以下，而HIER只有不到百分之二十五的视频流满足此要求。\n接着看图九，作者分别对卡顿率和快速启动率做了测量。在卡顿率指标上，用户观看视频时经历的卡顿次数（1、2、3、4、\u0026gt;=5）的概率相比HIER都有了显著的降低。另外在快速启动率指标上，LiveNet能够保证百分之九十五左右的快速启动率。作为对比，HIER只有百分之九十二左右。\n5 个人总结 本文作者针对阿里传统的层次型CDN架构所存在的问题，将节点和节点之间的路径转化成扁平的形式，带来的最明显的好处就是能够有效的减小CDN内部报文转发延迟。另外快慢路本质上是一种逻辑上的抽象，快路本质上是转发逻辑,负责报文的快速转发，绕开了TCP的复杂处理逻辑;而慢路本质上是控制逻辑，负责调整发送速率和重传报文。因此作者采用了RTCP和RTP协议来替代以往的RTMP协议，这本质上是一种工程上的考量，目的是为了解决现在的直播系统存在的问题——为了端到端延迟而服务。\n","date":1669294696,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1669294696,"objectID":"9519e45edab518dbb6e891169a838dc0","permalink":"https://ai4network.github.io/zh/post/paper-sharing-3/","publishdate":"2022-11-24T20:58:16+08:00","relpermalink":"/zh/post/paper-sharing-3/","section":"post","summary":" 本期分享SIGCOMM22主机网络和视频传输专题下的论文：LiveNet: a low-latency video transport network for large-scale live streaming。该文作者来自中国科学院大学和阿里巴巴集团。\n","tags":["paper sharing","SIGCOMM22","李亚辉"],"title":"SIGCOMM22 论文分享 | LiveNet: a low-latency video transport network for large-scale live streaming","type":"post"},{"authors":["徐草"],"categories":null,"content":"文献来源：SIGCOMM22\n文献题目：Achieving consistent low latency for wireless real-time communications with the shortest control loop\n摘要：Real-time communication (RTC) applications like video conferencing or cloud gaming require consistent low latency to provide a seamless interactive experience. However, wireless networks including WiFi and cellular, albeit providing a satisfactory median latency, drastically degrade at the tail due to frequent and substantial wireless bandwidth fluctuations. We observe that the control loop for the sending rate of RTC applications is inflated when congestion happens at the wireless access point (AP), resulting in untimely rate adaption to wireless dynamics. Existing solutions, however, suffer from the inflated control loop and fail to quickly adapt to bandwidth fluctuations. In this paper, we propose Zhuge, a pure wireless AP based solution that reduces the control loop of RTC applications by separating congestion feedback from congested queues. We design a Fortune Teller to precisely estimate per-packet wireless latency upon its arrival at the wireless AP. To make Zhuge deployable at scale, we also design a Feedback Updater that translates the estimated latency to comprehensible feedback messages for various protocols and immediately delivers them back to senders for rate adaption. Trace-driven and real-world evaluation shows that Zhuge reduces the ratio of large tail latency and RTC performance degradation by 17% to 95%.\n时间：2022/11/24 19:00-22:00\n地点：腾讯会议\n会议号：116-536-575\n会议密码：123456\n","date":1669289413,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1669289413,"objectID":"0816f060bb37ded54433f76b879c3fc9","permalink":"https://ai4network.github.io/zh/event/6/","publishdate":"2022-11-23T09:36:13+08:00","relpermalink":"/zh/event/6/","section":"event","summary":"文献来源：SIGCOMM22\n文献题目：Achieving consistent low latency for wireless real-time communications with the shortest control loop\n摘要：Real-time communication (RTC) applications like video conferencing or cloud gaming require consistent low latency to provide a seamless interactive experience.","tags":[],"title":"2022年秋季学期第15周论文分享","type":"event"},{"authors":["计晓岚"],"categories":["Paper Share"],"content":" 本期分享的论文是由微软研究院和MIT发表在SIGCOMM2022拥塞控制会议上的一篇文章。该文主要引入了一个新的度量：“弹性”，用来表征竞争时的交叉流量的性质。弹性捕获了交叉流量是否对可用带宽的变化作出反应这一属性。文章提出的NimbusCC在没有路由器支持的情况下，能够在发送端健壮地检测交叉流量的弹性，而且可以根据弹性检测来启用延迟控制拥塞控制协议，以达到减少延迟而不会损害吞吐量的目标。下面，我将具体地介绍该文的主要内容以及读后感言。\n研究动机 该文首先揭示了“延迟控制”的拥塞控制机制（例如Copa、Vegas等）与其他流量竞争时的性能问题：（1）当它和其他更具有带宽竞争力的“缓冲填充”的拥塞控制机制（例如Cubic、Reno等）竞争时，瓶颈链路的延迟增加后，“延迟控制”拥塞控制机制很快降低了发送速率，从而导致吞吐量低；（2）当它和固定比特率的流量（CBR）竞争时，不仅减少了延迟并且没有损失吞吐量；而对于“缓冲填充”的拥塞控制机制来说，和同类的机制以及CBR流竞争带宽时属公平竞争，但延迟都比较高。\n结合上述发现，该文得到了一个关键发现也就是它的研究目标：当发送方拥塞控制机制认为交叉流量是非弹性时，发送方可以使用“延迟控制”协议来减少发送方和交叉流量的延迟，而不用担心降低吞吐量。反之，如果是弹性的，它可以切换到TCP竞争的“缓冲填充”拥塞控制机制。这样能够更好地利用“延迟控制”机制，在具有带宽竞争力的同时，“安全”地降低延迟。\n关键技术 为了实现研究目标，该文首先总结并抽象了不同交叉流量进行带宽竞争时的一种属性：弹性。弹性表征了交叉流量在和其他流量竞争时，能够受其他流量带来的瓶颈可用带宽的影响，改变发送速率。比如一些应用限制的流量或者可用带宽超过比特率的视频流是不会对可用带宽变化而作出反应，因此为非弹性流。\n接下来，按照目标需要让发送方知道交叉流量的弹性属性，也就是需要进行弹性检测。这里提出的弹性检测是主动的，是鲁棒的。第一步，他们建立了如下图的交叉流量测速的模型，通过非空非满的瓶颈中，进出流量中发送方和交叉流所占比例守恒这一结论，能够在发送方进入瓶颈的速率S、接收速率R、以及瓶颈估计速率μ已知的情况下，得到交叉流量的速率Z。\n接着，他们并没有直接通过交叉流量速率来衡量弹性，而是通过主动增加发送方速率脉冲，然后根据交叉流会以相同频率响应脉冲的原理，在频域上分析交叉流的FFT，如果FFT在发送脉冲相应频率上具有更高的幅值，就证明更具有弹性。 最后，在发送方根据弹性阈值来切换NimbusCC的模式和应用机制，当交叉流是非弹性时，则应用“延迟控制”机制进行延迟控制模式，以此减少延迟并不损失吞吐量；而当交叉流是弹性时，切换TCP竞争模式，应用类似Cubic之类的机制公平竞争带宽，不考虑延迟问题。总结NimbusCC的整个流程如下图。 【模式切换】 实验验证 该文做了十分充分的实验验证，包括模拟和真实网络情况下，对于理想情况下的基于弹性检测和模式切换的拥塞控制的性能评估，也有一些不满足假设的情况下性能问题的评估等等。而下图就是对比不同的机制，评估NimbusCC在弹性/非弹性交叉流的背景下的吞吐量和延迟，发现NimbusCC在灰色区域的，竞争模式下比单纯的“延迟控制”机制更具有公平竞争带宽的能力；而在后60s，判断交叉流量是弹性的，切换为延迟控制模式，能够有效减少延迟，并且吞吐量和非弹交叉流公平竞争瓶颈带宽。\n个人观点 作为计算机网络领域顶级会议的文章，我认为它同时具备了发现问题的重要性，解决思路的创新性，以及实现技术的实用性。在拥塞控制研究这么多年的背景下，它发现了“延迟控制”这类机制在应用时的问题和现象。而解决问题的思路又不同于大部分能做到的方法创新，而首先基于“概念”创新，能够抽象并提出新的概念，并且具有一定的数理分析。最后，实际的实现技术时利用现有的一些拥塞控制的实现机制进行切换，简单而实用。所以，希望我们都能够从方法论创新走向思想创新，做更有用的研究吧！\n","date":1669031254,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1669031254,"objectID":"e7a1478607946aa7cedd9e0790b322c4","permalink":"https://ai4network.github.io/zh/post/paper-sharing-2/","publishdate":"2022-11-21T19:47:34+08:00","relpermalink":"/zh/post/paper-sharing-2/","section":"post","summary":" 本期分享的论文是由微软研究院和MIT发表在SIGCOMM2022拥塞控制会议上的一篇文章。该文主要引入了一个新的度量：“弹性”，用来表征竞争时的交叉流量的性质。弹性捕获了交叉流量是否对可用带宽的变化作出反应这一属性。文章提出的NimbusCC在没有路由器支持的情况下，能够在发送端健壮地检测交叉流量的弹性，而且可以根据弹性检测来启用延迟控制拥塞控制协议，以达到减少延迟而不会损害吞吐量的目标。下面，我将具体地介绍该文的主要内容以及读后感言。\n","tags":["paper sharing","SIGCOMM22","计晓岚"],"title":"SIGCOMM22 论文分享 | Elasticity Detection: A Building Block for Internet Congestion Control","type":"post"},{"authors":["宋丛溪"],"categories":["Paper Share"],"content":" 今天给大家介绍一篇NSDI22年的论文，这篇论文从层次编码的问题出发，利用自编码器对每一层的残差进行编码，并设计了single-shot和multi-exit机制用来降低解码延迟和根据用户计算资源动态调节解码，同时优化了自适应码率选择算法。\n一、问题提出 问题一： 当前的自适应码率选择算法难以预测实时的带宽变化，造成码率调节不准，从而影响视频播放质量。如图所示，蓝色的线为实时带宽，在60秒前，码率选择算法过高估计了带宽，选择了4K清晰度的码率，从而造成了播放卡顿的问题。在60-200秒，又过低估计了码率，造成长时间的收看清晰度低下。\n那么现在的码率选择算法还会产生什么问题呢？拿BOLA和BOLA-FS举例，BOLA对于带宽的变化响应很慢，带宽上升75秒后才进行了码率上调的响应，它的改进工作BOLA-FS虽然可以在感知到当前带宽利用不足的情况下进行高码率片段的下载，但是这样带来了带宽资源的浪费。\n层次编码可以很好地解决这个问题，因为层次编码不是将同一个视频端编码成多个码率的视频，而是一种层层增强的关系，如果发现当前码率不能较好利用带宽，可以通过请求增强层来增强视频质量，不会带来带宽的浪费。但是层次编码也会产生新的问题。\n问题二： 层次编码的第一个问题就是压缩比不如传统编码方式高，带来空间上的开销，原因是由于层次编码为了防止帧间漂移问题所以没有引入帧间预测。 第二个问题就是层次编码的解码时间开销较大，且随层次上升。也正是因为这两个问题，层次编码难以被大规模地应用。\n传统的层次压缩编码的压缩比和时间复杂度已经基本达到瓶颈了，所以基于学习的压缩越来越普遍。比如下图的基于利用自编码器（AutoEncoder(AE)）的编码，利用AE将视频或图像降维为成中间的”code”,从而达到压缩的目的。本文提出的Swift也是在此基础上进行的优化改进。\n二、方法设计 Swift的方法设计主要可以被分成三块：\nEncoder：编码器优化 Decoder：解码器优化 Streamer：码率选择算法优化 Encoder 首先来介绍Encoder方面的优化，编码器的设计如图所示：\n编码器（E）将每个在时间t的帧作为输入，生成一个代码向量(c)，即ct = E(It)。解码器（D）重建给定ct的帧 Iˆt ，即，Iˆt =D(ct)。这里的优化问题是要训练E和D，以使Iˆt 和D(ct)之间的差异最小它的差值最小，训练用损失函数如下式。为了使每层可以尽可能减少对于上一层的冗余信息，将Iˆt 和D(ct)之间的残差ri作为下一层的编码输入，即 ci = E(ri)。\n$$ \\mathcal{L}_{rec}=\\frac{1}{L}{\\sum\\limits_{i=0}^{L-1}}{\\Vert\\mathcal{D}(c_i)-r_i\\Vert}_1 $$ Decoder （1）Single-shot机制 为了解决上文提到的层次解码时间开销随层数线性增长的问题，本文设计了一种single-shot的解码机制，在一些层数的数据还无法解码时，直接用0填充，这样用较少的画面清晰度损失缓解解码开销对时延敏感型视频的影响，解码器的设计如下图所示。\n在此基础上，损失函数添加了一项关于画面质量的损失项。\n$$ \\mathcal{L}_{rec}=\\frac{1}{L}{\\sum\\limits_{i=0}^{L-1}}[\\underbrace{{\\Vert\\mathcal{D}(c_i)-r_i \\Vert}_1}_{residual\\ quality\\ loss}+ \\underbrace{{\\Vert\\mathcal{D}^{ss}(\\oplus_{k=0}^{i}c_k)-I\\Vert}_1}_{image\\ quality\\ loss}] $$ 如下图所示，因为single-shot机制的引入，视频的解码延迟不再随层数而增长。\n（2）Multi-exit机制 由于基于自编码器的视频编解码依赖于用户的GPU，所以我们也不得不靠考虑客户端主机的计算资源问题。为此，作者设计了一个multi-exit机制。机制的网络模型如下图所示\n即在解码器处设置了多个出口。作者在这里认为，出口所在层数越多，输出视频质量更好，测量了层数、出口深度和视频质量的关系，如这个热力图所示。\nStreamer 最后是码率选择算法(ABR)上的优化，码率选择算法主要解决的问题就是最大化流媒体传输的QoE，即最大化视频质量、卡顿时间、和平滑度的加权和。这里的算法设计基于2017年Sigcomm的工作Pensieve，一个基于强化学习的码率选择算法。在此基础上，作者为码率选择算法添加了一些新的输入，如当前的GPU可使用量、GPU和视频质量的映射矩阵等，输出的动作为请求的视频段和层数。\n下图为Swift的整体运行流程。\n三、实验效果 作者为衡量Swift的性能做了充分的实验。 实验一：各个码率选择算法对于当前网络带宽的响应速度。黑色的线为当前网络的带宽，我们可以看到绿色线代表的Swift可以在很短的时间内响应网络带宽的增加。\n实验二：各个码率选择算法带宽使用量的对比。可以看出，在同等的实验条件下，Swift占用的带宽是最低的，减少了网络资源的浪费。\n四、启发 虽然都是面向流媒体传输的优化，本文与我们之前专注的传输层方向是垂直的，它从编码和码率选择的角度去解决流媒体传输的问题，像是一种将网络的压力卸载到端上的操作。\n","date":1668990165,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1668990165,"objectID":"ca07806a3b1afa0ae01ad6b9eb8f2d75","permalink":"https://ai4network.github.io/zh/post/paper-sharing-1/","publishdate":"2022-11-21T08:22:45+08:00","relpermalink":"/zh/post/paper-sharing-1/","section":"post","summary":" 今天给大家介绍一篇NSDI22年的论文，这篇论文从层次编码的问题出发，利用自编码器对每一层的残差进行编码，并设计了single-shot和multi-exit机制用来降低解码延迟和根据用户计算资源动态调节解码，同时优化了自适应码率选择算法。\n","tags":["paper sharing","NSDI22","宋丛溪"],"title":"NSDI22 论文分享 | Swift: Adaptive Video Streaming with Layered Neural Codecs","type":"post"},{"authors":["徐草","韩雪强"],"categories":null,"content":"腾讯会议：899-899-777 会议密码：123456\n","date":1668799800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1668799800,"objectID":"251b1de394d8f5019d37ffcad765f219","permalink":"https://ai4network.github.io/zh/event/5/","publishdate":"2022-11-14T21:00:00Z","relpermalink":"/zh/event/5/","section":"event","summary":"腾讯会议：899-899-777 会议密码：123456","tags":[],"title":"2022年秋季学期第14周组会","type":"event"},{"authors":["李亚辉"],"categories":null,"content":"文献来源：SIGCOMM22\n文献题目：LiveNet: a low-latency video transport network for large-scale live streaming\n摘要：Low-latency live streaming has imposed stringent latency requirements on video transport networks. In this paper we report on the design and operation of the Alibaba low-latency video transport network, LiveNet. LiveNet builds on a flat CDN overlay with a centralized controller for global optimization. As part of this, we present our design of the global routing computation and path assignment, as well as our fast data transmission architecture with fine-grained control of video frames. The performance results obtained from three years of operation demonstrate the effectiveness of LiveNet in improving CDN performance and QoE metrics. Compared with our prior state-of-the-art hierarchical CDN deployment, LiveNet halves the CDN delay and ensures 98% of views do not experience stalls and that 95% can start playback within 1 second. We further report our experiences of running LiveNet over the last 3 years.\n腾讯会议：657-649-839 会议密码：123456\n","date":1668713400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1668713400,"objectID":"c6014a61480e6ec0fc45018bea04e666","permalink":"https://ai4network.github.io/zh/event/4/","publishdate":"2022-11-14T21:00:00Z","relpermalink":"/zh/event/4/","section":"event","summary":"文献来源：SIGCOMM22\n文献题目：LiveNet: a low-latency video transport network for large-scale live streaming\n摘要：Low-latency live streaming has imposed stringent latency requirements on video transport networks. In this paper we report on the design and operation of the Alibaba low-latency video transport network, LiveNet.","tags":[],"title":"2022年秋季学期第14周论文分享","type":"event"},{"authors":["宋丛溪"],"categories":null,"content":"文献来源：NSDI22\n文献题目：Swift: Adaptive Video Streaming with Layered Neural Codecs\n摘要：Layered video coding compresses video segments into layers (additional code bits). Decoding with each additional layer improves video quality incrementally. This approach has potential for very fine-grained rate adaptation. However, layered coding has not seen much success in practice because of its cross-layer compression overheads and decoding latencies. We take a fresh new approach to layered video coding by exploiting recent advances in video coding using deep learning techniques. We develop Swift, an adaptive video streaming system that includes i) a layered encoder that learns to encode a video frame into layered codes by purely encoding residuals from previous layers without introducing any cross-layer compression overheads, ii) a decoder that can fuse together a subset of these codes (based on availability) and decode them all in one go, and, iii) an adaptive bit rate (ABR) protocol that synergistically adapts video quality based on available network and client-side compute capacity. Swift can be integrated easily in the current streaming ecosystem without any change to network protocols and applications by simply replacing the current codecs with the proposed layered neural video codec when appropriate GPU or similar accelerator functionality is available on the client side. Extensive evaluations reveal Swift’s multi-dimensional benefits over prior video streaming systems.\n","date":1668195000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1668195000,"objectID":"23290c844810344482fafd5b726a7500","permalink":"https://ai4network.github.io/zh/event/3/","publishdate":"2022-11-10T21:00:00Z","relpermalink":"/zh/event/3/","section":"event","summary":"文献来源：NSDI22\n文献题目：Swift: Adaptive Video Streaming with Layered Neural Codecs\n摘要：Layered video coding compresses video segments into layers (additional code bits). Decoding with each additional layer improves video quality incrementally. This approach has potential for very fine-grained rate adaptation.","tags":[],"title":"2022年秋季学期第13周组会","type":"event"},{"authors":["计晓岚"],"categories":null,"content":"文献来源：SIGCOMM22\n文献题目：Elasticity detection: a building block for internet congestion control\n摘要：This paper introduces a new metric, “elasticity,” which characterizes the nature of cross-traffic competing with a flow. Elasticity captures whether the cross traffic reacts to changes in available bandwidth. We show that it is possible to robustly detect the elasticity of cross traffic at a sender without router support, and that elasticity detection can reduce delays in the Internet by enabling delay-controlling congestion control protocols to be deployed without hurting flow throughput. Our results show that the proposed method achieves more than 85% accuracy under a variety of network conditions, and that congestion control using elasticity detection achieves throughput comparable to Cubic but with delays that are 50–70 ms lower when cross traffic is inelastic.\n","date":1668108600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1668108600,"objectID":"d303344c85b881c12218c22fc6585664","permalink":"https://ai4network.github.io/zh/event/2/","publishdate":"2022-11-10T21:00:00Z","relpermalink":"/zh/event/2/","section":"event","summary":"文献来源：SIGCOMM22\n文献题目：Elasticity detection: a building block for internet congestion control\n摘要：This paper introduces a new metric, “elasticity,” which characterizes the nature of cross-traffic competing with a flow. Elasticity captures whether the cross traffic reacts to changes in available bandwidth.","tags":[],"title":"2022年秋季学期第13周文献分享","type":"event"},{"authors":["韩雪强"],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1663615800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1663615800,"objectID":"48a5e109fd33b789bfc7979587835871","permalink":"https://ai4network.github.io/zh/event/1/","publishdate":"2022-09-01T21:00:00Z","relpermalink":"/zh/event/1/","section":"event","summary":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.","tags":[],"title":"2022年秋季学期第6周组会","type":"event"},{"authors":null,"categories":null,"content":"Congratulations!\n","date":1663113600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1663113600,"objectID":"a66c907739bf26947a28ec86c19aa325","permalink":"https://ai4network.github.io/zh/post/ai4network_group_page_set/","publishdate":"2022-09-14T00:00:00Z","relpermalink":"/zh/post/ai4network_group_page_set/","section":"post","summary":"Congratulations!\n","tags":null,"title":"AI4network Group Homepage comes!","type":"post"},{"authors":["admin"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://ai4network.github.io/zh/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://ai4network.github.io/zh/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://ai4network.github.io/zh/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://ai4network.github.io/zh/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://ai4network.github.io/zh/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://ai4network.github.io/zh/tour/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"widget_page"}]